[
{
	"uri": "/aulas/",
	"title": "Conteúdo",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/aulas/0_eletrofisiologia/",
	"title": "Introdução a eletrofisiologia",
	"tags": [],
	"description": "",
	"content": "HIstória A história da eletrofisiologia começa na tentativa de identificar telepatia em humanos.\n 1929 - Hans Berger queria medir telepatia em humanos pela primeira vez: Como um soldado no exército alemão na primeira década de 1900, Hans Berger caiu de seu cavalo em frente de um carro de artilharia e quase foi atropelado. Quando ele voltou para o quartel, havia um telegrama de seu pai dizendo que sua irmã teve a “sensação” de que ele tinha sido ferido. Com essa motivação, Berger quis explorar manifestações físicas dessas transmissões psíquicas  1935 - Hallowell e Pauline Davis obtêm os primeiros registros de ERPs (potencial evocado). 1964 - Gray Walter reporta o primeiro componente cognitivo de ERP - era moderna da técnica 1964 - Sutton, Braren, Zubin e John descobrem o P300 1960: ERPlogy: estudo dos componentes do ERP 1980: Ressurgimento devido à popularização dos computadores   Eletroencefalograma EEG hoje Para aquisição de dados EEG, usualmente se utiliza equipamento de 128 eletrodos de posições delimitadas para medir atividade na superfície do córtex (medição de potencial elétrico).\nOs sinais elétricos detectados no couro cabeludo que têm origem não-cerebral são chamados de artefatos. A amplitude dos artefatos pode ser significativamente maior que a amplitude dos sinais corticais de interesse, o que facilita identificação das diferenças desses padrões.\nAlterações momentâneas na impedância de um determinado eletrodo pode causar “spikes”.\nNos casos do sinais de Eletroencefalografia (EEG), temos o ruído da rede elétrica que no Brasil é 60 Hz. Muitos laboratórios utilizam gaiola de Faraday para amenizar o problema (isolamento da energia), mas ainda assim a filtragem é necessária para garantir a qualidade do sinal coletado.\nAlém desses existem outros artefatos como ondas de baixas frequências devido a temperatura da cabeça do indivíduo. Deste modo, é extremamente importante aplicação de filtros nestes sinais para remoção de tais artefatos antes de qualquer outra análise.\nDas análises mais comuns realizadas com EEG, estão: ERP - Potenciais relacionados ao evento e Análise Espectral.\nPotencial relacionado ao evento - ERP O potencial evocado ou resposta evocada é um potencial elétrico registrado do sistema nervoso de um humano ou outro animal seguido da apresentação de um estímulo, distinto dos potenciais espontâneos detectados por eletroencefalografia (EEG).\n Análise espectral Com potenciais induzidos, com mudanças no tempo (eixo x), quando não há sincronia no tempo no experimento entre os voluntários, é utilizada a análise espectral.\nA análise de Fourier consiste na separação do sinal em vários componentes senoidais (soma de senos). As senóides são a base que levam qualquer ponto no espaço, nesse caso, é possível transportar qualquer sinal (finito).\nSNC A transformada de Fourier pega os sinais em várias frequências distintas e devolve as frequências fundamentais.\n Wavelets Análises cuidadosas dos registros do eletroencefalograma (EEG) podem fornecer informações valiosas sobre esse distúrbio disseminado do cérebro. A Wavelet é uma ferramenta de análise de tempo e frequência eficaz para a análise de sinais transientes. Suas propriedades de extração e representação de características podem ser usadas para analisar vários eventos transitórios em sinais biológicos.\n    "
},
{
	"uri": "/aulas/1_intror/",
	"title": "Introdução ao R",
	"tags": [],
	"description": "",
	"content": "Introdução ao R - comandos O R é um software importante para análise de dados estatísticos. Apesar de não ter uma interface gráfica , a usabilidade é melhor para personificação das análises e permite mais opções para visualização e análise de dados.\nVetor e matrizes no R: Para armazenar um valor a uma variável, simplesmente usamos:\nx = 3.7 O vetor é uma estrutura de dados básica do R, que permite armazenar um conjunto de valores numéricos ou de caractere sob um mesmo tipo.\nx = c(1, 2, 3, 4) x ## [1] 1 2 3 4 Para criar um vetor com repetidos valores, por exemplo uma repetição de zeros, utiliza-se:\nx = array(0, 100) x ## [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## [36] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## [71] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Para criar uma matriz, utiliza-se uma estrutura similar.\nx = matrix(1, 2, 2) x ## [,1] [,2] ## [1,] 1 1 ## [2,] 1 1 Atribuindo algum valor (1000) ao intervalo, no caso primeira linha:\nx[1,]=1000 # Saída da matriz inteira com 1000 na primeira linha e 1 no resto: x ## [,1] [,2] ## [1,] 1000 1000 ## [2,] 1 1 Caso queira exibir uma única linha ou coluna, basta digitar o comando com a linha ou coluna desejada:\n# Coluna x[,2] ## [1] 1000 1 #Linha: x[2,] ## [1] 1 1  Listas no R: Listas são objetos que podem armazenar objetos de dados de tipos diferentes. É possível incluir data.frames, arrays, matrizes, vetores, fatores e mesmo listas em uma lista.\nlist=list() list$nome = \u0026quot;joao\u0026quot; list$idade = 40 list$vetor=c(1,2,3) list$nome ## [1] \u0026quot;joao\u0026quot; # Saída: list ## $nome ## [1] \u0026quot;joao\u0026quot; ## ## $idade ## [1] 40 ## ## $vetor ## [1] 1 2 3  Loops R: Para realizar uma repetição com variável de controle, o comando for() incrementa um índice dentro de uma sequência de valores.\nfor(i in 1:10){ print (i) } ## [1] 1 ## [1] 2 ## [1] 3 ## [1] 4 ## [1] 5 ## [1] 6 ## [1] 7 ## [1] 8 ## [1] 9 ## [1] 10 Para reaizar uma repetição pré-testada, o teste para sair do laço de repetição é realizado antes de entrar no laço, e para isso utilizamos a função while():\ni=1 while(i\u0026lt;=10){ print (i) i=i+1 } ## [1] 1 ## [1] 2 ## [1] 3 ## [1] 4 ## [1] 5 ## [1] 6 ## [1] 7 ## [1] 8 ## [1] 9 ## [1] 10 Ou outro exemplo:\ni=1 while(i\u0026lt;=10){ print (i) if (i\u0026lt;=5) { print(\u0026quot;menor ou igual a 5\u0026quot;) } else{ print(\u0026quot;maior que 5\u0026quot;) } i=i+1 } ## [1] 1 ## [1] \u0026quot;menor ou igual a 5\u0026quot; ## [1] 2 ## [1] \u0026quot;menor ou igual a 5\u0026quot; ## [1] 3 ## [1] \u0026quot;menor ou igual a 5\u0026quot; ## [1] 4 ## [1] \u0026quot;menor ou igual a 5\u0026quot; ## [1] 5 ## [1] \u0026quot;menor ou igual a 5\u0026quot; ## [1] 6 ## [1] \u0026quot;maior que 5\u0026quot; ## [1] 7 ## [1] \u0026quot;maior que 5\u0026quot; ## [1] 8 ## [1] \u0026quot;maior que 5\u0026quot; ## [1] 9 ## [1] \u0026quot;maior que 5\u0026quot; ## [1] 10 ## [1] \u0026quot;maior que 5\u0026quot; No R, o índice i for imutável, recomenda-se utilizar o “for” como opção de repetição.\n Outras funções úteis no R: A Estatística Descritiva está diretamente ligada à organização e descrição dos dados. É utilizada para sumarizar como as observações se distribuem e onde estão posicionadas (ex.: medidas de tendência central e dispersão) e como se apresentam em termos de associação. Os conceitos e métodos descritivos são ponto de partida da análise exploratória de dados, passo fundamental para análises estatísticas mais avançadas.\nConsiderando a matriz criada x,\nx ## [,1] [,2] ## [1,] 1000 1000 ## [2,] 1 1 temos as seguintes funções para estatística descritiva:\n# Média: mean(x) ## [1] 500.5 # Desvio padrão sd(x) ## [1] 576.7729 # Distribuição normal: rnorm(x) ## [1] -0.82708705 0.40291164 -0.06741388 0.05212912 # Boxplot: boxplot(x)   Leitura de dados de ECG A primeira vista, pode parecer contraintuitivo que num curso de Processamento de Sinais Neurais contenha análise de dados de Eletrocardiograma (ECG). Dentre os parâmetros que podem ser aferidos a partir do ECG é a frequência cardíaca (número de batimentos do coração que acontecem a cada minuto - bpm). A freqüência cardíaca é capaz de indicar uma ativação geral do sistema nervoso autônomo, responsável por controlar nossas reações corporais involuntárias. Ao expor uma pessoa em situações de maior demanda energética, o coração bate mais forte e mais rápido.\nO uso do ECG fornece dados informativos acerca dos processos psicofisiológicos em diversas situações, sendo altamente aplicável em estudos que investigam as respostas comportamentais como por exemplo de consumidores ou outros entrevistados.\nLeitura de dados de ECG: Na aula o professor disponibilizou dados de um arquivo em que ele coletou dados de ECG de si mesmo (a partir de um arduino). O arquivo contém uma única coluna que é o valor em mV coletado com o instrumento:\ndados = read.table(\u0026quot;ecg.txt\u0026quot;, header = FALSE) Para visualizar os dados da forma de série temporal, utiliza-se a função ts.plot(). Algumas versões do R Studio contém um problema para visualização dos dados, então utiliza-se a seguinte gambiarra recomendada pelo Stackoverflow:\n# Pra não dar erro \u0026quot;figure margins too large\u0026quot; no ts.plot: graphics.off() par(\u0026quot;mar\u0026quot;) ## [1] 5.1 4.1 4.1 2.1 par(mar=c(1,1,1,1)) Após implementar essas linhas, na sequência, visualizamos os dados com a função:\n# Plotando gráfico de linha - ECG ts.plot(dados) Um histograma pode ajudar a melhorar a visualização da amplitude do sinal:\nhist(dados$V1) Para fins de referência, consideremos como picos de batimentos os valores com resultados acima de 685mV, então destacaríamos os maiores:\n# Para percorrer todas as casas dos dados, detectando os picos: picos=array(0, nrow(dados)) for(i in 1:960){ if(dados$V1[i]\u0026gt;685){ picos[i]=1 } } # Unindo no plot as colunas de dados e picos ts.plot(cbind(dados$V1, picos)) # Como pode ver, ficou zoado, então ajustamos a escala e adicionamos cores para que se possa visualizar os dados: # cores: col 2 = preto e 1 vermelho ts.plot(cbind(dados$V1, picos+684), col=c(2,1)) O ajuste ainda não ficou muito claro. Toda vez que encontrar um pico, os valores conseguintes referem-se ao mesmo pico, ou seja, devemos limpar os dados (retirada de picos contínuos adjacentes). Neste caso, escolhemos ignorar os picos dos 10 dados seguintes ao primeiro pico.\nNota: Para percorrer o vetor completo, basta percorrer o código até os 10 últimos (critério de parada) dados. Os demais picos seriam ignorados de qualquer forma e poderia reproduzir erro no vetor.\nDessa forma, teríamos:\nfor(i in 1:(nrow(dados)-10) ){ if(picos[i]==1){ picos[(i+1):(i+10)]=0 } } ts.plot(cbind(dados$V1,picos+684),col=c(2,1))   "
},
{
	"uri": "/aulas/2_filtro_sinais/",
	"title": "Filtros de sinais",
	"tags": [],
	"description": "",
	"content": "O processo de filtragem de sinais permite a caracterização dos sinais a partir de suas características. Por exemplo, aplicado ao som as frequências mais altas representam os sons mais agudos, enquanto que as frequências mais baixas representam os sons mais graves.\nOs artefatos em EEG caracterizam de ondas não cerebrais, denominadas por ruídos, como por exemplo a frequência da rede elétrica de 60hz, ondas de baixas frequências devido ao calor no couro cabeludo do indivíduo. Deste modo, é extremamente importante aplicação de filtros nestes sinais para remoção de tais artefatos antes de qualquer outra análise.\nPara tratar esses sinais, seja, frequências altas, baixas ou algum determinado intervalo, definimos um filtro passa baixa a partir da subtração do sinal original pela média aritmética dos pontos ao redor. Alguns conceitos importantes para a construção dos filtros:\n Frequência de amostragem: Trata-se da frequência de sinais observados em um intervalo de tempo (medidos em hertz = 1/s).  Ex: No EEG utiliza-se uma frequência de 250 por segundo. Com FNIRS, utiliza-se em torno de 7 frames por segundo. Na ressonância magnética funcional (fMRI), temos 1 imagem a cada 2 segundos. Logo, a frequência de amostragem é 1/2 = 0.5Hz Observação: A frequência = 1/período da observação  Frequência de Nyquist: Corresponde à metade da frequência da taxa amostragem. Pelo teorema de Nyquist, para prevenir o aliasing (sobreposição de sinais) deve-se:aumentar da taxa de amostragem até duas vezes da maior frequência do sinal. Se o sinal é limitado no tempo a frequência de amostragem deve ser tão alta quanto se conseguir, pois em frequência o sinal se espalha por todo o espectro sendo não limitado; com isso deve-se remover ou filtrar as frequências acima da frequência mais alta desejada evitando a formação do aliasing  Note: A frequência de Nyquist vale para qualquer modalidade de técnica de neuroiumagem (fMRI,EEG,fNIRS…).   O filtro permite a passagem o sinal de parte dos dados e impede a retirada de outros. São os filtros:\n Passa-alta (High pass): Deixa passar as altas frequências (maior importância pra alta frequência e baixa importáncia para baixa frequência.\n Passa-baixa (Low pass): Deixa passar as baixas frequências e dá pouca importância às altas frequências.\n Passa-banda (band pass): O sinal resultante após o filtro possui apenas a banda de frequência utilizada no filtro.\n  Implementação de filtros em R e carregando dados: No R faremos primeiro o desenho do filtro: ou seja definir qual o tipo de frequências vamos passar, para isso usaremos o comando “butter” no pacote signal.\nCaso não tenha o pacote, utilize os comandos:\nInstalando pacote de sinais no R: * install.packages(“signal”)\ne no código chamar a blbioteca\nrequire(signal) O exercício da aula mostra a leitura de um banco de dados de sinais de EEG.\nPara isso, será necessário realizar a leitura dos dados:\nsinais=read.table(\u0026quot;oddball250hz.txt\u0026quot;,header=FALSE) ver também a verificação dos dados:\ndim(sinais) ## [1] 45461 33 Olhando o arquivo, ele é composto por 45461 linhas e 33 colunas (essas referentes aos 32 canais e uma última coluna de zeros).\nPara verificar os dados do arquivo em um plot:\n# Plot da série temporal: #gambiarra para o ts.plot funcionar no R Studio: graphics.off() par(\u0026quot;mar\u0026quot;) ## [1] 5.1 4.1 4.1 2.1 par(mar=c(1,1,1,1)) e o plot:\n# Plotando gráfico de linha ts.plot(sinais) A taxa de amostragem é a frequência em que a leitura ocorre: * HZ=1/INTERVALO, onde 1hz = 1/s\n# Suponha que o sinal foi adquirido sob uma taxa de amostragem de 250Hz: HZ= 250 Dessa forma, analisamos o sinal com base nessa amostragem, para todas as linhas, para o canal 5, com o plot do tipo l (linha):\n#Fazer gráfico com frescura: # plot(1:nrow(sinais), sinais[,5],type=\u0026quot;l\u0026quot;) # mas preciso considerar a frequência convertendo pra segundos: plot((1:nrow(sinais))/HZ, sinais[,5], type=\u0026quot;l\u0026quot;, xlab=\u0026quot;Tempo(s)\u0026quot;, ylab= \u0026quot;sinal uV\u0026quot;)  Utilizando a função do filtro (butter): Primeiramente se define qual o tipo de frequências vamos passar, para isso usaremos o comando “butter”. A função butter possui a seguinte síntaxe: * butter (n = ordem do filtro, w = cutoff, tipo = tipo de filtro) onde, + ordem do filtro = controla o decaimento da curva de ajuste do filtro, geralmente se usa 3 ou 5. + cutoff = frequências que se queira cortar (é um número de 0 a 1, neste caso é preciso fazer uma regra de 3; 0 = 1 e 1= frequências de Nyquist) + type = tipo de filtro (low/passa-baixa, high/passa-alta ou band-pass/passa banda)\nAplicando passa-baixa em 30Hz:\nFILTRO = butter(n=5, W =30/(HZ/2), type = \u0026quot;low\u0026quot;) # Gráfico do desenho do filtro: freqz(FILTRO) Após ter o filtro desenhado, aplica-lo sobre os dados do canal (neste caso seria o canal 5, como exemplo, mas poderia ser qlq um). Ao aplicar o filtro de forma direta teríamos ainda um problema:\nfiltrado_teste = filter(FILTRO, sinais[,5]) # bug de início do sinal, com valor muito alto. Neste caso “bugado” teríamos o seguinte retorno:\n#Fazer o grafico com os 2 sinais plot((1:nrow(sinais))/HZ, sinais[,5],type=\u0026quot;l\u0026quot;, xlab=\u0026quot;Tempo(s)\u0026quot;, ylab=\u0026quot;sinal(uV)\u0026quot;) #Acrescentar linha com o sinal filtrado lines((1:nrow(sinais))/HZ, filtrado_teste, col=2) Para isso resolve-se tirando a média do sinal:\ny = sinais[,5] - mean(sinais[,5]) # e novamente aplicando o filtro no sinal: filtrado = filter(FILTRO, y) obtendo então o sinal filtrado:\n#Acrescentar linha com o sinal filtrado plot((1:nrow(sinais))/HZ,y,type=\u0026quot;l\u0026quot;, xlab=\u0026quot;Tempo(s)\u0026quot;, ylab=\u0026quot;sinal(uV)\u0026quot;) lines((1:nrow(sinais))/HZ, filtrado, col=2) Dessa forma é possível aplicar outros filtros, alterando o tipo na função butter e aplicando aos sinais de todos os canais na função filter. Dica de exercício: Tente executar para outros canais ou então ajustando o filtro para outras frequências ou determinados intervalos de frequência.\nUm exemplo comum é a aplicação de um filtro que processe dados de um determinado intervalo (por exemplo, como a rede elétrica é 60hz mas há oscilações, processa-se sinal entre 59-61hz). Neste caso, queremos um passa-banda para deixar apenas entre as frequências de 1-40 hz:\n# butter (n = ordem do filtro, w = cutoff, tipo = tipo de filtro) # - n = Ordem do filtro = controla o decaimento da curva de ajuste do filtro, # geralmente se usa 3 ou 5. # -type = tipo de filtro (low/passa-baixa, high/passa-alta ou band-pass/passa banda) FILTRO = butter(n=5, W =c(1,40)/(HZ/2), type = \u0026quot;pass\u0026quot;) freqz(FILTRO) Quero aplicar este filtro em todas as colunas da matriz de sinais, realizando a retirada da média para tirar os outliers antes do filtro. O sinal bruto permanece sem o ajuste das médias, então para executar em todos os canais, é importante que y esteja nas interações:\nfsinais = matrix(0, nrow(sinais), ncol(sinais)) for (canal in 1:32) { y = sinais[,canal] - mean(sinais[,canal]) fsinais[,canal]=filter(FILTRO,y) } Para verificar o sinal bruto e filtrado de cada canal, tirando a média (o exemplo contempla o canal 1):\n#Checar o sinal bruto e filtrado plot((1:nrow(sinais))/HZ,sinais[,1]-mean(sinais[,1]),type=\u0026quot;l\u0026quot;,xlab=\u0026quot;Tempo(s)\u0026quot;, ylab=\u0026quot;sinal(uV)\u0026quot;) lines((1:nrow(sinais))/HZ,fsinais[,1],col=2) Observações sobre a implementação de filtros: 1. Adicionar a taxa de amostragem atribuindo um valor para HZ.\n Passa-baixa em 30hz: ** FILTRO = butter(n=5, W = 30/(HZ/2), type = “low”)\n Passa-banda para deixar apenas entre as frequências de 1-40 hz: ** FILTRO = butter(n=5, W = c(1,40)/(HZ/2), type = “pass”)\n Passa-alta para frequências acima de 0.2hz: ** FILTRO = butter(n=5, W = 0.2/(HZ/2), type = “high”)\n   "
},
{
	"uri": "/aulas/3_potenciaisevocados/",
	"title": "Potenciais Evocados",
	"tags": [],
	"description": "",
	"content": "Potencial relacionado a evento (ERP, do inglês Event-Related Potential), é uma resposta direta do cérebro a um específico estímulo cognitivo, sensorial, ou motor. ERPs são obtidos por promediação (no tempo).\nOs componentes são designados por uma letra (N - negative / P - positive), seguido de um número que pode indicar tanto a latência em ms como a posição da componente na forma de onda.\nAlguns exemplos de ERPs e suas devidas funções:\n P1 (ou P100) concentraram-se em observar as variações deste potencial durante estimulação visual. Pesquisas posteriores sobre o P1 começaram a olhar para alterações do P1 em relação à atenção seletiva. Sua amplitude máxima é observada sobre o lobo occipital, contralateral ao campo visual no qual o estímulo é apresentado. O N1 (também chamado de N100) é o primeiro componente negativo contínuo e o seu pico é normalmente observado entre 80 e 160 ms após o aparecimento do estímulo. Forte sobre a região fronto-central do couro cabeludo. Embora a maioria das pesquisas se concentra em estímulos auditivos, o N100 também ocorre para estimulação visual, olfativa e táctil. O N100 é pré-atencional e diretamente envolvido na percepção porque sua amplitude é fortemente dependente de coisas como o tempo de subida de um som, sua intensidade, o intervalo entre estímulos e a frequência comparativa, ou seja, sua amplitude aumenta em proporção a quanto um som difere em frequência de um som precedente. O P2 (P200) potencial positivo que ocorre cerca de 200 milissegundos frequentemente distribuído em torno das áreas centro-frontal e parieto-occipital do couro cabeludo. Sua associação ainda está em desenvolvimento pois há um grande e diversificado número de tarefas cognitivas associadas a essa componente. N2, ou N200, encontrada principalmente na parte anterior do couro cabeludo em resposta a estímulos auditivos inesperados ou raros,com ou sem atenção, é referido como a negatividade de incompatibilidade (mismatch negativity – MMN). Mais genericamente, foi descrito em tarefas que refletem a identificação de estímulos, deslocamentos atencionais, inibição de respostas motoras, superação de respostas estereotípicas ou monitoramento de conflitos, manutenção de informações de contexto, seleção de respostas, timing, e detecção de novidade (novelty) ou incompatibilidade (mismatch). P3 (P300) tipicamente medido mais fortemente pelos eletrodos que cobrem o lobo parietal, está suscitado no processo de tomada de decisão. Mais especificamente, considera-se que o P300 reflete processos envolvidos na avaliação ou categorização do estímulo. Geralmente é provocado usando o paradigma oddball, em que eventos alvo (ou “raro”) de baixa probabilidade são misturados com itens não-alvo (ou “padrão”) de alta probabilidade  Outros componentes de ERP mais tardios, como por exemplo o N400 e o P600 são muito usados na área de neurociência da linguagem. Os componentes mais pesquisados na literatura ainda são o N1 e o P3.\nOs dados deste material são de estímulos sonoros, um agudo e um grave em que o indivíduo deveria clicar no mouse ao ouvir o estímulo agudo.\n# Leitura dos dados sinais=read.table(\u0026quot;oddball250hz.txt\u0026quot;,header=FALSE) Para continuar a leitura dos filtros, deve-se realizar a leitura dos dados de canais também disponibilizados:\n# Leitura dos canais de EEG: nomes=scan(\u0026quot;nomecanais.txt\u0026quot;, what = \u0026quot;string\u0026quot;) Ao analisar o arquivo dos sinais, é possível verificar que a coluna 33 não se trata de sinais cerebrais, mas sim, a referência dos triggers (marcações do experimento). Dessa forma, realiza-se a leitura dos sinais e dos triggers, armazenando em matrizes separadas:\n# Separar o trigger dos sinais # Jogo fora o sinal 33 porque não é dado cerrebral trigger = sinais[,33] sinais= sinais[,1:32] Analisando a matriz trigger com o comando table, é possível verificar os tipos de eventos existentes no experimento (eventos raros marcados por 10 e frequentes marcados por 11):\n# Lendo o conteúdo do trigger: # esse comendo mostra o número de observações de cada tipo table(trigger) ## trigger ## 0 10 11 ## 45422 10 29 Olhando o conteúdo do trigger:\n# Conteúdo do vetor do trigger: ts.plot(trigger) Para identificação dos potenciais evocados, precisamos ainda definir os canais (a matriz sinais já exclui a coluna de trigger do arquivo) e pontos no tempo (número de linhas do arquivo):\n# Número de canais: Ncanais =ncol(sinais) # Número de pontos no tempo: T=nrow(sinais) Filtrando os sinais de todos os canais:\nFILTRO = butter(n=5, W =c(1,40)/(HZ/2), type = \u0026quot;pass\u0026quot;) freqz(FILTRO) fsinais = matrix(0, nrow(sinais), ncol(sinais)) for (canal in 1:32) { y = sinais[,canal] - mean(sinais[,canal]) fsinais[,canal]=filter(FILTRO,y) } plot((1:nrow(sinais))/HZ,sinais[,1]-mean(sinais[,1]),type=\u0026quot;l\u0026quot;,xlab=\u0026quot;Tempo(s)\u0026quot;, ylab=\u0026quot;sinal(uV)\u0026quot;) lines((1:nrow(sinais))/HZ,fsinais[,1],col=2) Considerando a taxa de amostragem de 250hz, quero calcular uma determinada janela no intervalo 100ms dado um canal:\n# Se a taxa de amostragem é HZ= 250, quero definir as janelas pré e pós estímulos, ou seja 1s = 250hz, 100ms = 250hz/10: JANELApos=HZ #janela de 1 segundo JANELApre=HZ/10 #janela de 100 milisegundos O comando which ajuda a separar os estímulos:\n#Descobrir quais as caselas do vetor trigger se referem ao estimulo freq e raro TiRaro= which(trigger==10) #estimulo raro TiFreq= which(trigger==11) #estimulo frequente Armazenando os potenciais evocados do estímulo raro:\n# Matriz que guarda os potenciais evocados medios do estimulo raro ti=1000 PERaro=matrix(0,length((ti-JANELApre):(ti+JANELApos)), Ncanais) # for pra cada canal for(canal in 1:Ncanais){ for(ti in TiRaro){ BASELINE=mean(fsinais[(ti-JANELApre):ti,canal]) y=fsinais[(ti-JANELApre):(ti+JANELApos),canal]-BASELINE PERaro[,canal]= PERaro[,canal]+y/length(TiRaro) } } Por exemplo, olhando a legenda no arquivo, nomedoscanais, vemos que o canal Fz se refere ao canal 5. Desa forma, o gráfico:\n#Fazer o grafico do potencial evocal no canal Fz. coluna 5 # estimulo acontece em milisegundos (ms) por isso converto com a taxa de # amostragem plot((1:nrow(PERaro))/HZ*1000-100, PERaro[,5],type=\u0026quot;l\u0026quot;, xlab=\u0026quot;Tempo(ms)\u0026quot;, ylab=\u0026quot;Sinal(uv)\u0026quot;) abline(v=0,lty=3) Agora armazenando os potenciais evocados do estímulo frequente:\n#Matriz que guarda os potenciais evocados medios de todos os canais PEFreq=matrix(0,length((ti-JANELApre):(ti+JANELApos)), Ncanais) #Calculo para todos os canais for(canal in 1:Ncanais){ for(ti in TiFreq){ BASELINE=mean(fsinais[(ti-JANELApre):ti, canal]) y=fsinais[(ti-JANELApre):(ti+JANELApos), canal] -BASELINE PEFreq[,canal] = PEFreq[,canal]+ y/length(TiFreq) } #fecha o for do ti } #fecha o for do canal #Fazer o grafico do potencial evocal no canal Fz. coluna 5 plot((1:nrow(PEFreq))/HZ*1000-100, PEFreq[,5], type=\u0026quot;l\u0026quot;, xlab=\u0026quot;Tempo(ms)\u0026quot;, ylab=\u0026quot;Sinal(uv)\u0026quot;) abline(v=0,lty=3) Para conseguir fazer uma comparação entre os potenciais evocados, adicionamos os dois gráficos conjuntamente. Sendo nas cores Preta para estímulo frequente e vermelho para estímulo raro.\n#Fazer o grafico do potencial evocal no canal Fz. coluna 5 #Do estimulo raro e frequente no mesmo grafico plot((1:nrow(PEFreq))/HZ*1000-100, PEFreq[,5],type=\u0026quot;l\u0026quot;, xlab=\u0026quot;Tempo(ms)\u0026quot;,ylab=\u0026quot;Sinal(uv)\u0026quot;,ylim=c(-7,7)) lines((1:nrow(PERaro))/HZ*1000-100, PERaro[,5],col=2) abline(v=0,lty=3) Obs: os valores arbitrários em ylim foram ajustes manuais para alinhar a visualização superior e inferior das linhas, ao fazer o plot de ambas poderia ter feito melhor, mas sabe como a vida é…\nAnalisando esse tipo de gráfico, é possível ver diferença entre os estímulos. Claro que para ter significância estatística precisaria de uma avaliação mais profunda para poder confirmar a real existência dessa diferença.\nFazer o plot da diferenca do PE raro e frequente no canal Pz, coluna 25:\ncanal=25 plot((1:nrow(PEFreq))/HZ*1000-100, PERaro[,canal]-PEFreq[,canal],type=\u0026quot;l\u0026quot;,xlab=\u0026quot;Tempo(ms)\u0026quot;, ylab=\u0026quot;sinal(uV)\u0026quot;,ylim=c(-8,4)) abline(v=0,lty=3) Resumo: Na questão de potenciais evocados, trabalhamos com as médias dos sinais. Basicamente visam dois objetivos:\n Sinal de EEG é extremamente ruidoso (artefatos musculares e do ambiente). Aumentar o SNR - signal-to-noise ratio (ou relação sinal-ruído em português)\n Extrair “componente”\u0026quot; comum entre os trials\n   "
},
{
	"uri": "/aulas/4_epocas/",
	"title": "Controle de qualidade",
	"tags": [],
	"description": "",
	"content": "O número de tentativas necessárias para obter um ERP depende de vários fatores, sendo o mais importante a “relação sinal-ruído” (Signal to Noise Ratio), ou seja, o tamanho relativo do sinal (o ERP) em relação ao tamanho do ruído. Em experimentos cognitivos, 30 a 50 apresentações de estímulo são normalmente necessárias para se obter um ERP médio bom e limpo.\nIdentificação de épocas (períodos dos estímulos) num experimento. O número de épocas (trials) aumenta a SNR.\nO código implementado abaixo foram calculados os ERPs associados aos dois tipos de estímulos (raros e frequentes) de um experimento. O sinal foi corrigido pela média do baseline, com a média de várias repetições para remoção de ruídos existentes.\n#Leitura de dados sinais=read.table(\u0026quot;OlhosFechados.txt\u0026quot;,header=FALSE) #Nome dos canais nomescanais=scan(\u0026quot;NOMEScanais.txt\u0026quot;,what=\u0026quot;string\u0026quot;) dim(sinais) ## [1] 45315 32 nomescanais ## [1] \u0026quot;Fp1\u0026quot; \u0026quot;Fp2\u0026quot; \u0026quot;F7\u0026quot; \u0026quot;F3\u0026quot; \u0026quot;Fz\u0026quot; \u0026quot;F4\u0026quot; \u0026quot;F8\u0026quot; \u0026quot;FC5\u0026quot; \u0026quot;FC1\u0026quot; \u0026quot;FC2\u0026quot; ## [11] \u0026quot;FC6\u0026quot; \u0026quot;T7\u0026quot; \u0026quot;C3\u0026quot; \u0026quot;Cz\u0026quot; \u0026quot;C4\u0026quot; \u0026quot;T8\u0026quot; \u0026quot;TP9\u0026quot; \u0026quot;CP5\u0026quot; \u0026quot;CP1\u0026quot; \u0026quot;CP2\u0026quot; ## [21] \u0026quot;CP6\u0026quot; \u0026quot;TP10\u0026quot; \u0026quot;P7\u0026quot; \u0026quot;P3\u0026quot; \u0026quot;Pz\u0026quot; \u0026quot;P4\u0026quot; \u0026quot;P8\u0026quot; \u0026quot;PO9\u0026quot; \u0026quot;O1\u0026quot; \u0026quot;Oz\u0026quot; ## [31] \u0026quot;O2\u0026quot; \u0026quot;PO10\u0026quot; Para saber o período de aquisição dos dados, basta dividir o número de linhas por 32:\n# Considerando taxa de amostragem e convertendo pra minutos: 45315/(200*60) ## [1] 3.77625 # Conteúdo do vetor do trigger: ts.plot(sinais) Para definição das épocas dos eventos (intervalos dos trials), precisamos identificar as amplitudes dos intervalos e assinalar na matriz os intervalos de tempo entre os eventos:\nComandos importantes:\n round(): arredondamento matemático\n floor(): arredondamento para baixo\n ceiling(): arredondamento para cima\n  # Análisando uma época de 5s numa taxa de amostragem de 200hz: # Considerando o tamanho de 5s, seria: # TAM = seg * HZ = 5 * 200 HZ = 200 # taxa de amostragem considerada: TamSegundos=5 # Numero de segundos do trial: TAM = TamSegundos*HZ Nepocas = floor(nrow(sinais)/TAM) Ncanais = ncol(sinais) # Inicializar a matriz com as amplitudes de cada epoca para cada canal: #Inicializar a matriz com as amplitudes de cada epoca para cada canal AMPLITUDE= matrix(0, Nepocas, Ncanais) for(canal in 1:Ncanais){ for(epoca in 1:Nepocas){ #Casela de inicio da epoca INICIO=(epoca-1)*TAM+1 #Casela de fim da epoca FIM=epoca*TAM #Calculo de amplitude AMPLITUDE[epoca,canal]=max(sinais[INICIO:FIM,canal])- min(sinais[INICIO:FIM,canal]) }#for da epoca }#for dos canais Para analisar os dados da amplitude, podemos ver a distribuição no histograma abaixo:\n#Analisar a distribuicao das amplitudes hist(c(AMPLITUDE)) Limitando um pouco a visualização, no caso em 150:\nLIMIAR=150 #escolhido analisando o histograma Criando uma matriz de controle de qualidade de dimensão idêntica ao da matriz AMPLITUDE. O ZERO corresponde a épocas sem problemas e UM são as épocas onde a amplitude foi maior que um limiar:\nCQ = matrix(0, Nepocas, Ncanais) CQ[which(AMPLITUDE\u0026gt;LIMIAR)]=1 Para identificar os CANAIS mais problemáticos e realizar a contagem das épocas descartadas em cada canal:\ncolSums(CQ) ## [1] 8 2 4 1 1 0 0 2 0 0 0 11 6 0 1 8 10 0 0 1 1 9 4 ## [24] 0 1 3 9 10 1 3 7 3 Unindo as colunas dos canais com as épocas descartadas:\ncbind(nomescanais,colSums(CQ)) ## nomescanais ## [1,] \u0026quot;Fp1\u0026quot; \u0026quot;8\u0026quot; ## [2,] \u0026quot;Fp2\u0026quot; \u0026quot;2\u0026quot; ## [3,] \u0026quot;F7\u0026quot; \u0026quot;4\u0026quot; ## [4,] \u0026quot;F3\u0026quot; \u0026quot;1\u0026quot; ## [5,] \u0026quot;Fz\u0026quot; \u0026quot;1\u0026quot; ## [6,] \u0026quot;F4\u0026quot; \u0026quot;0\u0026quot; ## [7,] \u0026quot;F8\u0026quot; \u0026quot;0\u0026quot; ## [8,] \u0026quot;FC5\u0026quot; \u0026quot;2\u0026quot; ## [9,] \u0026quot;FC1\u0026quot; \u0026quot;0\u0026quot; ## [10,] \u0026quot;FC2\u0026quot; \u0026quot;0\u0026quot; ## [11,] \u0026quot;FC6\u0026quot; \u0026quot;0\u0026quot; ## [12,] \u0026quot;T7\u0026quot; \u0026quot;11\u0026quot; ## [13,] \u0026quot;C3\u0026quot; \u0026quot;6\u0026quot; ## [14,] \u0026quot;Cz\u0026quot; \u0026quot;0\u0026quot; ## [15,] \u0026quot;C4\u0026quot; \u0026quot;1\u0026quot; ## [16,] \u0026quot;T8\u0026quot; \u0026quot;8\u0026quot; ## [17,] \u0026quot;TP9\u0026quot; \u0026quot;10\u0026quot; ## [18,] \u0026quot;CP5\u0026quot; \u0026quot;0\u0026quot; ## [19,] \u0026quot;CP1\u0026quot; \u0026quot;0\u0026quot; ## [20,] \u0026quot;CP2\u0026quot; \u0026quot;1\u0026quot; ## [21,] \u0026quot;CP6\u0026quot; \u0026quot;1\u0026quot; ## [22,] \u0026quot;TP10\u0026quot; \u0026quot;9\u0026quot; ## [23,] \u0026quot;P7\u0026quot; \u0026quot;4\u0026quot; ## [24,] \u0026quot;P3\u0026quot; \u0026quot;0\u0026quot; ## [25,] \u0026quot;Pz\u0026quot; \u0026quot;1\u0026quot; ## [26,] \u0026quot;P4\u0026quot; \u0026quot;3\u0026quot; ## [27,] \u0026quot;P8\u0026quot; \u0026quot;9\u0026quot; ## [28,] \u0026quot;PO9\u0026quot; \u0026quot;10\u0026quot; ## [29,] \u0026quot;O1\u0026quot; \u0026quot;1\u0026quot; ## [30,] \u0026quot;Oz\u0026quot; \u0026quot;3\u0026quot; ## [31,] \u0026quot;O2\u0026quot; \u0026quot;7\u0026quot; ## [32,] \u0026quot;PO10\u0026quot; \u0026quot;3\u0026quot; Agora identificando as ÉPOCAS mais problemáticas e verificar as épocas com problemas em mais de um canal:\nrowSums(CQ) ## [1] 11 7 9 5 2 4 2 2 2 4 15 15 4 3 2 1 0 0 0 0 0 0 0 ## [24] 0 0 1 3 0 3 1 1 0 2 1 2 0 1 2 0 0 1 0 0 0 0 Olhando um canal específico (ex: Fp1) na época 11:\nepoca=11 INICIO=(epoca-1)*TAM+1 FIM=epoca*TAM ts.plot(sinais[INICIO:FIM,1]) "
},
{
	"uri": "/aulas/5_transformadas/",
	"title": "Análise Espectral",
	"tags": [],
	"description": "",
	"content": "O conteúdo dessa aula auxilia no entendimento da amostragem no domínio da frequência e reconstrução de sinais de tempo discreto. No quesito de análise de dados com EEG, os processos de transformação de amostras do domínio do tempo para o domínio da frequência. Estas incluem tanto a análise direta do espectro de frquência, bem como convoluções. Existem variações relacionadas com a transformada, dependendo do tipo de cada função.\nA análise espectral decompõe o sinal de EEG em suas componentes fundamentais (harmônicos) que geram frequências conhecidas que podem ser distinguidas entre si.\nO sinal de EEG é composto de várias outras ondas, de modo que a análise espectral consiste em realizar uma decomposição da onda de EEG em diversas ondas senoidais (ou cossenoides). Essa decomposição consiste na aplicação da transformada de Fourier.\nA transformada de Fourier converte uma seqüência finita de amostras igualmente espaçadas de uma função em uma seqüência de comprimento igual de amostras igualmente espaçadas da transformada de Fourier em tempo discreto (DTFT), que é uma função de frequência de valor complexo (na literatura poderá conferir que muitas vezes o número imaginário \\(i\\) pode ser representado como \\(j\\) para evitar possíveis confusões com intensidade de corrente, também representadas pelo mesmo símbolo).\nO intervalo no qual o DTFT é amostrado é recíproco a duração da sequência de entrada. Uma DFT inversa é uma série de Fourier, possuindo os mesmos valores de amostra da seqüência de entrada original. A DFT é, portanto, considerada uma representação do domínio da frequência da sequência de entrada original. Se a sequência original abranger todos os valores diferentes de zero de uma função, seu DTFT é contínuo (e periódico), e o DFT fornece amostras discretas de um ciclo. Se a sequência original é um ciclo de uma função periódica, a DFT fornece todos os valores diferentes de zero de um ciclo de DTFT.\nO sinal de EEG de: \\(X_T = \\{X_0, X_1, ..., X_{t-1}\\}\\) é denotado pela decomposição:\n\\[ \\begin{align} C_{k} = \\sum_{T=0}^{t-1} X_{T} \\hspace{1mm} \\sin(\\lambda_k T+\\phi) \u0026amp;\u0026amp; \\text{(sendo} \\lambda_k= \\frac{2\\pi i}{N} \\text{a frequência de Fourier)} \\end{align} \\]\nPelas relações trigonométricas:\n\\[ \\begin{align} \\sin(\\lambda t+ \\phi) = \\sin(\\lambda t) \\cos(\\phi) + \\sin(\\phi)\\cos(\\lambda t) \u0026amp;\u0026amp; \\text{(soma de arcos)}\\\\ e^{jx} = \\cos(x)+j\\sin(x) \u0026amp;\u0026amp; \\text{(forma de Euler)} \\end{align} \\]\npode-se representar a decomposição do sinal de EEG como:\n\\[C_{k} = \\sum_{T=0}^{t-1} X_{T} \\hspace{1mm} e^\\frac{-2\\pi k i}{T}\\]\nT = 100 lambda1 = 30 lambda2 = 50 lambda3 = 110 x= sin(2*pi*lambda1*(1:T)/T) +0.5*sin(2*pi*lambda2*(1:T)/T) +0.25*sin(2*pi*lambda3*(1:T)/T) ## [1] 1.469463e-01 2.377641e-01 2.377641e-01 1.469463e-01 -5.514005e-16 ## [6] -1.469463e-01 -2.377641e-01 -2.377641e-01 -1.469463e-01 1.102801e-15 ## [11] 1.469463e-01 2.377641e-01 2.377641e-01 1.469463e-01 1.221552e-16 ## [16] -1.469463e-01 -2.377641e-01 -2.377641e-01 -1.469463e-01 2.205602e-15 ## [21] 1.469463e-01 2.377641e-01 2.377641e-01 1.469463e-01 -9.806459e-16 ## [26] -1.469463e-01 -2.377641e-01 -2.377641e-01 -1.469463e-01 -2.443104e-16 ## [31] 1.469463e-01 2.377641e-01 2.377641e-01 1.469463e-01 1.469267e-15 ## [36] -1.469463e-01 -2.377641e-01 -2.377641e-01 -1.469463e-01 4.411204e-15 ## [41] 1.469463e-01 2.377641e-01 2.377641e-01 1.469463e-01 -3.186248e-15 ## [46] -1.469463e-01 -2.377641e-01 -2.377641e-01 -1.469463e-01 1.961292e-15 ## [51] 1.469463e-01 2.377641e-01 2.377641e-01 1.469463e-01 -7.363355e-16 ## [56] -1.469463e-01 -2.377641e-01 -2.377641e-01 -1.469463e-01 -4.886208e-16 ## [61] 1.469463e-01 2.377641e-01 2.377641e-01 1.469463e-01 1.713577e-15 ## [66] -1.469463e-01 -2.377641e-01 -2.377641e-01 -1.469463e-01 -2.938533e-15 ## [71] 1.469463e-01 2.377641e-01 2.377641e-01 1.469463e-01 -1.004737e-14 ## [76] -1.469463e-01 -2.377641e-01 -2.377641e-01 -1.469463e-01 8.822409e-15 ## [81] 1.469463e-01 2.377641e-01 2.377641e-01 1.469463e-01 -7.597453e-15 ## [86] -1.469463e-01 -2.377641e-01 -2.377641e-01 -1.469463e-01 6.372496e-15 ## [91] 1.469463e-01 2.377641e-01 2.377641e-01 1.469463e-01 -5.147540e-15 ## [96] -1.469463e-01 -2.377641e-01 -2.377641e-01 -1.469463e-01 3.922584e-15 ts.plot(x) Ruído-branco Gaussiano é um sinal aleatório com igual intensidade em diferentes frequências, o que lhe dá uma densidade espectral de potência constante. Em termos discretos, é um sinal discreto cujas amostras são vistas como uma seqüência de variáveis aleatórias não autocorrelacionadas com média zero e variância finita. Para calcular o espectro, utiliza-se a transformada de Fourier: A Transformada rápida de Fourier (em inglês fast Fourier transform, ou FFT) é um algoritmo eficiente para se calcular a Transformada discreta de Fourier (DFT) e a sua inversa. A análise de Fourier converte um sinal do seu domínio original para uma representação no domínio da frequência e vice-versa. Idêntico à definição se T for potência de 2 (ou aproximação de).\nA função spectrum realiza a estimativa da densidade espectral de uma série temporal.\nhist(rnorm(T)) x = x+rnorm(T) ts.plot(x) A função spectrum realiza a estimativa da densidade espectral de uma série temporal. O estimador do espectro (periodograma) é definido como “estimado” pois ele faz uma estimativa e não uma média de todos os dados gerados.\nEssa análise espectral verifica o valor da amplitude da onda para cada frequência de Fourier. Em EEG, existe um grupo de faixas de frequências que aparecem em situações especificas e a análise espectral permite visualizar o comportamento da amplitude das ondas de EEG para cada um desses grupos, de acordo com o objetivo do estudo, identificando as bandas de frequências:\n Delta \u0026lt;4z Teta 4-7hz Alfa 8-12hz Beta 13-30hz Gama \u0026gt; 30hz  O periodograma no R, gráfico com as frequências é determinado por:\nESPECTRO = spectrum(x) # O eixo x ficaria em plot(ESPECTRO$freq, ESPECTRO$spec, type = \u0026quot;l\u0026quot;) Implementando com o banco de dados Realizando a leitura dos dados:\n#leitura dos sinais sinais=read.table(\u0026quot;OlhosFechados.txt\u0026quot;,header=FALSE) #leitura do nome dos canais nomescanais=scan(\u0026quot;NOMEScanais.txt\u0026quot;,what=\u0026quot;string\u0026quot;) dim(sinais) ## [1] 45315 32 nomescanais  ## [1] \u0026quot;Fp1\u0026quot; \u0026quot;Fp2\u0026quot; \u0026quot;F7\u0026quot; \u0026quot;F3\u0026quot; \u0026quot;Fz\u0026quot; \u0026quot;F4\u0026quot; \u0026quot;F8\u0026quot; \u0026quot;FC5\u0026quot; \u0026quot;FC1\u0026quot; \u0026quot;FC2\u0026quot; ## [11] \u0026quot;FC6\u0026quot; \u0026quot;T7\u0026quot; \u0026quot;C3\u0026quot; \u0026quot;Cz\u0026quot; \u0026quot;C4\u0026quot; \u0026quot;T8\u0026quot; \u0026quot;TP9\u0026quot; \u0026quot;CP5\u0026quot; \u0026quot;CP1\u0026quot; \u0026quot;CP2\u0026quot; ## [21] \u0026quot;CP6\u0026quot; \u0026quot;TP10\u0026quot; \u0026quot;P7\u0026quot; \u0026quot;P3\u0026quot; \u0026quot;Pz\u0026quot; \u0026quot;P4\u0026quot; \u0026quot;P8\u0026quot; \u0026quot;PO9\u0026quot; \u0026quot;O1\u0026quot; \u0026quot;Oz\u0026quot; ## [31] \u0026quot;O2\u0026quot; \u0026quot;PO10\u0026quot; Parametrizando as variáveis iniciais:\n#Taxa de amostragem HZ=250 #Tamanho da epoca (janela) em segundos TAMsegundos=5 #Tamanho da epoca (janela) em caselas do vetor de sinais TAM=TAMsegundos*HZ #Numero de epocas Nepocas=floor(nrow(sinais)/TAM) #Numero de canais Ncanais=ncol(sinais) Criando matriz Espectro para armazenar a média dos periodogramas entre todas as épocas para cada canal. As linhas representam diferentes frequências As colunas representam os canais\nESPECTRO=matrix(0,TAM/2,Ncanais) #Calcular para cada canal # Escondi a saída de todos os espectros porque tem muitos canais e épocas na saída for(canal in 1:Ncanais){ y=0 #Calcula a media entre épocas for(epoca in 1:Nepocas){ #Descobrir caselas de inicio e fim de cada epoca INICIO=TAM*(epoca-1)+1 FIM=epoca*TAM y=y+spectrum(sinais[INICIO:FIM,canal], plot = FALSE)$spec }#for da epoca ESPECTRO[,canal]=y/Nepocas }#for do canal  Gráfico do espectro no canal O1, coluna 29. plot((HZ/2)*(1:nrow(ESPECTRO))/nrow(ESPECTRO), ESPECTRO[, 29], type=\u0026quot;l\u0026quot;, xlab=\u0026quot;Frequencia (Hz)\u0026quot;, ylab=\u0026quot;Potencia (uV^2)\u0026quot;) Ajustando o zoom para conseguir visualizar a informação melhor:\nIX=10:200 plot((HZ/2)*IX/nrow(ESPECTRO), ESPECTRO[IX,29], type=\u0026quot;l\u0026quot;,xlab=\u0026quot;Frequencia (Hz)\u0026quot;,ylab=\u0026quot;Potencia (uV^2)\u0026quot;) #Armazenar o espectro estimado médio de olhos fechados ESPECTROof=ESPECTRO Para armazenar o espectro estimado médio de olhos abertos e colocar os dois no mesmo gráfico:\nESPECTROoa=ESPECTRO ##### COLOCAR OS 2 espectros médios no mesmo grafico #ZOOM no grafico IX=10:200 plot((HZ/2)*IX/nrow(ESPECTROof), ESPECTROof[IX,29], type=\u0026quot;l\u0026quot;,xlab=\u0026quot;Frequencia (Hz)\u0026quot;,ylab=\u0026quot;Potencia (uV^2)\u0026quot;) legend(\u0026quot;topright\u0026quot;,c(\u0026quot;Olhos Fechados\u0026quot;,\u0026quot;Olhos Abertos\u0026quot;),lty=c(1,1), col=c(1,2)) No gráfico podemos o espectro para cada frequência (analisar o espectro para cada faixa) e não a evolução em si (pois não está no tempo).\n "
},
{
	"uri": "/aulas/6_eyetracker/",
	"title": "Eye Tracking",
	"tags": [],
	"description": "",
	"content": "A tecnologia de eye tracking (ET) permite o rastreamento ocular, o que possibilita sua aplicação em diversas áreas das ciências, como saúde, psicologia e até mesmo marketing. O aparelho realiza a gravação do comportamento ocular, ou seja, identificando a localização do olhar, a duração de tempo, a dilatação da pupila e o trajeto do olhar. A importância desta técnica se deve ao fato de que o olhar de um indivíduo está diretamente relacionado com a sua atenção, o que faz com que seja possível compreender, em parte, o processo cognitivo de um usuário.\nA distância entre o reflexo que sai da pupila e o reflexo da luz observado na córnea é o que permite identificar a localização do olhar de uma pessoa, esse ponto onde a pessoa fixa o olhar é chamado de “fixação”. A fixação geralmente dura entre 100 e 500 ms (milissegundos). O trajeto que se produz entre duas fixações é chamado de sacada (saccade).\nA hipótese trabalhada nesse tópico é baseada na relação entre as substâncias noradrelina e norepinefrina que associadas ao núcleos cerúleos permitem realizar a seguinte associação: * Aumento da atividade cerebral \\(\\rightarrow\\) dilatação da pupila * Repouso o sistema parassimpático $a pupila se contrai.]\nConforme ocorre a dilatação do diâmetro da pupila, podemos fazer inferências sobre a atividade cerebral dos indivíduos, como por exemplo determinando uma média dos sinais referentes ao diâmetro da pupila e comparar esses valores entre as condições de repouso e tarefa.\n#leitura de dados dados=read.table(\u0026quot;dadosEYE.txt\u0026quot;,header=TRUE,sep=\u0026quot;;\u0026quot;) dim(dados) ## [1] 9099 30 Para ler as primeiras linhas (só pra saber a cara da tabela sem olhar tudo):\nhead(dados) ## RecordingTime..ms. Time.of.Day..h.m.s.ms. Trial Stimulus ## 1 221104.5 21:41:01:349 Trial001 brian-1-recording.avi ## 2 221137.8 21:41:01:382 Trial001 brian-1-recording.avi ## 3 221170.9 21:41:01:415 Trial001 brian-1-recording.avi ## 4 221204.4 21:41:01:449 Trial001 brian-1-recording.avi ## 5 221237.5 21:41:01:482 Trial001 brian-1-recording.avi ## 6 221270.8 21:41:01:515 Trial001 brian-1-recording.avi ## Export.Start.Trial.Time..ms. Export.End.Trial.Time..ms. Participant ## 1 0 302726 brian ## 2 0 302726 brian ## 3 0 302726 brian ## 4 0 302726 brian ## 5 0 302726 brian ## 6 0 302726 brian ## Color Tracking.Ratio.... Category.Group Category.Binocular ## 1 Coral 100 Eye - ## 2 Coral 100 Eye Visual Intake ## 3 Coral 100 Eye Visual Intake ## 4 Coral 100 Eye Visual Intake ## 5 Coral 100 Eye Visual Intake ## 6 Coral 100 Eye Visual Intake ## Index.Binocular Pupil.Diameter.Right..mm. ## 1 - 4.6 ## 2 1 4.6 ## 3 1 4.6 ## 4 1 4.6 ## 5 1 4.6 ## 6 1 4.6 ## Point.of.Regard.Binocular.X..px. Point.of.Regard.Binocular.Y..px. ## 1 693.0 258.7 ## 2 690.1 257.0 ## 3 692.4 257.2 ## 4 692.2 257.5 ## 5 694.2 256.3 ## 6 691.5 257.2 ## Point.of.Regard.Right.X..px. Point.of.Regard.Right.Y..px. ## 1 739.9 271.6 ## 2 739.4 269.7 ## 3 742.4 270.5 ## 4 743.3 269.9 ## 5 743.8 268.9 ## 6 741.0 270.5 ## AOI.Name.Binocular Gaze.Vector.Right.X Gaze.Vector.Right.Y ## 1 - 0 0 ## 2 - 0 0 ## 3 - 0 0 ## 4 - 0 0 ## 5 - 0 0 ## 6 - 0 0 ## Gaze.Vector.Right.Z Video.Time..h.m.s.ms. Annotation.Name ## 1 1 00:00:00:083 - ## 2 1 00:00:00:083 - ## 3 1 00:00:00:125 - ## 4 1 00:00:00:167 - ## 5 1 00:00:00:208 - ## 6 1 00:00:00:250 - ## Annotation.Description Annotation.Tags Mouse.Position.X..px. ## 1 - - - ## 2 - - - ## 3 - - - ## 4 - - - ## 5 - - - ## 6 - - - ## Mouse.Position.Y..px. Scroll.Direction.X Scroll.Direction.Y Content ## 1 - - - - ## 2 - - - - ## 3 - - - - ## 4 - - - - ## 5 - - - - ## 6 - - - - (assim é possível verificar se está tudo ok e se não tem problema algum com os arquivos)\nA função “colnames”\u0026quot; ajuda a identificar o nome das colunas.\n#Leia os nomes das colunas colnames(dados) ## [1] \u0026quot;RecordingTime..ms.\u0026quot; \u0026quot;Time.of.Day..h.m.s.ms.\u0026quot; ## [3] \u0026quot;Trial\u0026quot; \u0026quot;Stimulus\u0026quot; ## [5] \u0026quot;Export.Start.Trial.Time..ms.\u0026quot; \u0026quot;Export.End.Trial.Time..ms.\u0026quot; ## [7] \u0026quot;Participant\u0026quot; \u0026quot;Color\u0026quot; ## [9] \u0026quot;Tracking.Ratio....\u0026quot; \u0026quot;Category.Group\u0026quot; ## [11] \u0026quot;Category.Binocular\u0026quot; \u0026quot;Index.Binocular\u0026quot; ## [13] \u0026quot;Pupil.Diameter.Right..mm.\u0026quot; \u0026quot;Point.of.Regard.Binocular.X..px.\u0026quot; ## [15] \u0026quot;Point.of.Regard.Binocular.Y..px.\u0026quot; \u0026quot;Point.of.Regard.Right.X..px.\u0026quot; ## [17] \u0026quot;Point.of.Regard.Right.Y..px.\u0026quot; \u0026quot;AOI.Name.Binocular\u0026quot; ## [19] \u0026quot;Gaze.Vector.Right.X\u0026quot; \u0026quot;Gaze.Vector.Right.Y\u0026quot; ## [21] \u0026quot;Gaze.Vector.Right.Z\u0026quot; \u0026quot;Video.Time..h.m.s.ms.\u0026quot; ## [23] \u0026quot;Annotation.Name\u0026quot; \u0026quot;Annotation.Description\u0026quot; ## [25] \u0026quot;Annotation.Tags\u0026quot; \u0026quot;Mouse.Position.X..px.\u0026quot; ## [27] \u0026quot;Mouse.Position.Y..px.\u0026quot; \u0026quot;Scroll.Direction.X\u0026quot; ## [29] \u0026quot;Scroll.Direction.Y\u0026quot; \u0026quot;Content\u0026quot; A primeira coluna se traz os “RecordingTime..ms.” Para saber a taxa de amostragem, precisamos avaliar a diferença entre elementos. Entre um MILISEGUNDO e outro, temos um intervalo de sinais coletados.\n#Tomando os 10 primeiros números dados[1:10,1] ## [1] 221104.5 221137.8 221170.9 221204.4 221237.5 221270.8 221304.0 ## [8] 221337.5 221370.7 221403.9 Para conhecer a taxa de amostragem fazemos um elemento menos o anterior, para isso usamos o comando “diff” e tiramos a média:\n Identificando a diferença dos elementos com o elemento anterior:   #Identificamos a diferença entre um elemento menos o anterior, para isso usamos o comando \u0026quot;diff\u0026quot;: diff(dados[,1])  O cálculo da média proporciona a identificação do intervalo, e dessa forma é possível identificar a taxa de amostragem:   DIFF = mean(diff(dados$RecordingTime..ms.)) #A taxa de amostragem em Hertz é dada por: HZ=1000*1/DIFF No caso do cálculo da frequência, HZ, está multiplicado por 1000 pois a coleta está em milisegundos e a frequência tem que considerar segundos.\nVisualizando a informação:\n#Fazer o grafico plot(dados$RecordingTime..ms.*1000, dados$Pupil.Diameter.Right..mm.,type=\u0026quot;l\u0026quot;,xlab=\u0026quot;Tempo(s)\u0026quot;, ylab=\u0026quot;Diametro Pupilar Direito(mm)\u0026quot;) Neste gráfico pode-se identificar piscadas (que não necessariamente é um artefato, pois piscada está associada a estados cognitivos).\nPara essa análise, pretendemos identificar os picos de cima e os de baixo (muito sensíveis posso considerar como missing data).\nIdentificando o diâmetro da pupila direita e os dados que quero ignorar:\n#Sinal do diametro da pupila direita pupilD = dados$Pupil.Diameter.Right..mm. #Detectar outliers, piscadas e missing data IX=which(pupilD\u0026lt;4 | pupilD\u0026gt;6) pupilD[IX]=NA Delineamento do experimento: * 30 segundos em repouso seguidos de 30s de tarefa (repetindo ciclo), fazendo a subtração de 13 a partir do 2000 (e decrescendo!) * Cada época de 30s se refere a HZ30 caselas no vetor pupilD.  Devemos criar um vetor indicando a condição para cada casela do vetor pupilD: * O vetor CONDICAO armazenará os dois tipos de estímulos existentes, inicialmente marcado como 1 para todos os dados\nCONDICAO = array(1, length(pupilD)) Durante os períodos de contagem de subtração mental (a cada 30s) há um repouso:\n# identificando o inicio do intervalo, com base nos 30s de trial: inicio = ceiling(HZ*30) # calculando o teto, que é o final do trial, 30s depois: final = ceiling((HZ*30)+(HZ*30)) Calculando as condições (para aula fizemos de uma forma manual para ficar mais rápido). O recomendado mesmo seria reproduzir as linhas acima num laço e identificar as condições e intervalos.\nUma vez identificado os períodos do trial, atualizar o vetor CONDICAO para os parâmetros para 2 nos intervalos em que ocorre o estímulo:\n#Colocar 2 nas caselas durante os periodos de subtracao mental CONDICAO[902:1803]=2 CONDICAO[2706:3607]=2 CONDICAO[4510:5411]=2 CONDICAO[6314:7215]=2 CONDICAO[8118:9019]=2 Analisando as duas condições (repouso e atividade), podemos visualizar com boxplot:\n#Boxplot do diametro de pupila nas duas condicoes #os proximos 2 comandos sao equivalentes boxplot(pupilD[which(CONDICAO==1)],pupilD[which(CONDICAO==2)]) boxplot(pupilD~CONDICAO) Além disso, queremos avaliar a transição repouso da tarefa para cada bloco em cada região.\nOlhando apenas uma condição:\nplot(1:1803,pupilD[1:1803],type=\u0026quot;l\u0026quot;) Olhando todas as condições:\nplot(1:1803,pupilD[1:1803],type=\u0026quot;l\u0026quot;) lines(1:1804,pupilD[1804:3607],col=2) lines(1:1804,pupilD[3608:5411],col=3) lines(1:1804,pupilD[5412:7215],col=4) lines(1:1804,pupilD[7216:9019],col=6) É possível ver uma tendência dos dados. Para uma visualização melhor dos dados, analisamos a curva média da pupila nesses períodos:\n#calcular a curva media MEDIA=(pupilD[1:1804]+pupilD[1804:3607]+pupilD[3608:5411]+pupilD[5412:7215]+pupilD[7216:9019])/5 No caso do plot, estamos multiplicando por 60 por se tratar de um ciclo de 30s de atividade e 30s de repouso:\nplot(60*(1:1804)/1804,MEDIA,type=\u0026quot;l\u0026quot;,xlab=\u0026quot;Tempo(s)\u0026quot;,ylab=\u0026quot;Diametro(mm)\u0026quot;) abline(v=30,lty=3) A dificuldade nestes exercícios é a identificação das caselas a serem trabalhadas.\nmediarep = mean(pupilD[which(CONDICAO==1)]) # Desvio padrão da condição repouso: desviorep = sd(pupilD[which(CONDICAO==1)]) # Media da condição tarefa: media = mean(pupilD[which(CONDICAO==2)]) # Desvio padrão da condição tarefa: desviopad = sd(pupilD[which(CONDICAO==2)]) "
},
{
	"uri": "/aulas/7_ressonanciamagnetica/",
	"title": "Ressonância magnética",
	"tags": [],
	"description": "",
	"content": "Imagens estruturais T1 e Voxel-based-morphometry (VBM) A Ressonância Magnética (RM) é um método de diagnóstico por imagem, estabelecido na prática clínica, utilizada em pesquisas científicas e diagnósticos clínicos. Dada a alta capacidade de diferenciar tecidos e coletar informações bioquímicas, o espectro de aplicações se estende a todas as partes do corpo humano e explora aspectos anatômicos e funcionais. A física da Ressonância Magnética Nuclear (RMN) aplicada à formação de imagens é complexa e abrangente, uma vez que tópicos como eletromagnetismo, supercondutividade e processamento de sinais têm de ser abordados em conjunto para o entendimento deste método, usando fortes campos magnéticos e ondas de rádio para obtenção de imagens de múltiplas partes do corpo. Esta revisão tem por objetivo explorar de forma introdutória e simplificada a física da imagem por ressonância magnética e demonstrar equipamentos, mecanismos e aplicações da RM, servindo como texto de apoio para o aprofundamento do assunto.\nAs imagens cerebrais de ressonância magnética podem ser separadas em duas grandes categorias: a estrutural, que lida com o estudo da estrutura do cérebro e o diagnóstico de doenças e lesões, e a funcional que é capaz de detectar variações no fluxo sanguíneo em resposta à atividade neural.\nComo não consegui explicar bem o fenômeno, segue a explicação das notas de aula da Cândida Barreto:\nOs núcleos atômicos contêm prótons e nêutrons com movimento intrínseco de rotação. Os Prótons contêm carga elétrica, podemos considerar que a carga elétrica do próton é distribuída e rotacional ao longo do eixo central. A Distribuição de carga em movimento de rotação produzem um campo magnético de modo que o arranjo é análogo a um imã, tal que o próton pode ser visto como um dipolo magnético.\nEm muitos núcleos os prótons e nêutrons estão emparelhados de tal forma que seus spins e momentos magnéticos se cancelam. Núcleo com número ímpar de prótons e nêutrons exibe spin e momento magnético. O átomo de hidrogênio possui um único próton e é o elemento mais abundante no corpo, tal que este gera o sinal de ressonância magnética nuclear mais forte entre os núcleos. Normalmente os momentos magnéticos nucleares têm direção aleatória. Sob ação de um forte campo magnético estático externo o próton vai se comportar como uma pequena bússola e a direção do seu momento magnético tende a se alinhar ao campo externo.\nA detecção do sinal do sinal de RMN é feita a partir da perturbação no vetor de magnetização de tal forma a torná-lo mensurável. É feito uma Irradiação dos prótons por um sinal de rádio frequência (RF) com fótons de energia igual à diferença entre os estados que provoca a transição de um certo número de prótons para o estado antiparalelo, de modo que, ao retirar o estimo de RF ocorre um relaxamento longitudinal de modo que \\(M_0\\) volta ao estado paralelo. Já na componente transversal, o pulso de RF oscila com frequência igual à frequência dos prótons (Frequência de Larmor), de modo que os prótons começam a precessionar em fase, produzindo um sinal magnético coerente que pode ser medido.\nFrequência de Larmor: Em 1897, o físico inglês Joseph Larmor (1857-1942) demostrou que o efeito de um campo magnético sobre partículas carregadas que descrevem órbitas circulares era o de superpor à frequência precessional em torno do campo externo, conhecida desde então como Frequência de Larmor.\nA expressão da frequência de Larmor do movimento de precessão nuclear é:\n\\(\\nu =\\omega _{0}/2\\pi\\)\nNo caso do hidrogênio:\n$ = 42.58 mh z /tesla $\nNa RM clínica: \\(0.5 - 1.5 Tesla\\)\nO método de neuroestimulação cerebral teve seus primeiros estudos nos anos 90. Novas pesquisas revelam que é eficaz e tem dado sinais de que será cada vez mais usado. Alguns hospitais e clínicas começam a oferecê-lo no Brasil.\nA diferença entre T1 e T2 está na intensidade de sinal baseada em tempos de relaxamento T1, o TR da sequência é encurtado. Uma sequência de TR curto e TE curto produz uma imagem ponderada em T1. Isso permite que estruturas com tempos de relaxamento T1 curtos sejam brilhantes (gordura, líquidos proteinogênicos) e estruturas com T1 longo sejam escuras (neoplasia, edema, inflamação, líquido puro). As imagens ponderadas em T2 já não são muito nítidas e são utilizadas para analises da ressonância magnética funcional(fMRI). Assim, de modo geral, a criação de uma imagem por RMN pode ser descrita pelos seguintes passos:\n Aplicar campo magnético estático.  Selecionar corte aplicando campo magnético em gradiente.  Aplicar pulsos de RF.  Receber sinal de RF.  Converter o sinal em imagem.   A neuroestimulação pode ser feita de duas formas: * a) com um aparelho que libera ondas magnéticas (estimulação magnética transcraniana) e é colocado próximo da cabeça * b) com eletrodos implantados no cérebro (estimulação elétrica)\nA estimulação magnética transcraniana tem sido útil no tratamento de pacientes com depressão, transtorno bipolar (alternância entre depressão e euforia) e alucinações auditivas (um dos sinais da esquizofrenia). Os sintomas tornam-se mais brandos ou desaparecem.\nO método não requer cirurgia. Exames de imagem determinam o ponto do cérebro que precisa ser estimulado. Com base nessa referência, o médico aplica a técnica no consultório.\nA Potência do aparelho é avaliada pela intensidade do campo magnético, ou seja, do seu magnetismo. Em clínicas o equipamento varia entre menos de 1, até 3 Tesla.\n Potência abaixo de 1 Tesla São equipamentos de campo aberto, usados para realizar exames de extremidades corporais, com baixa qualidade de imagens.  Potência de 1 Tesla: Está presente nos aparelhos fabricados até 2002. Tem desenho de campo pouco eficiente, poucas funcionalidades e imagens de baixa qualidade. Utilizados no campo veterinário hoje em dia.  Potência de 1,5 Tesla: São mais comuns nas clínicas de radiologia. É o suficiente para a maioria dos exames e realizado de rotinas nos exames médicos.  Potência de 3 Tesla: Se encaixa no que chamávamos na residência de equipamento de pesquisa e que acaba sendo incorporado na rotina. O problema aqui são os dispositivos implantáveis antigos como marcapassos que não possuem proteção suficiente para o campo magnético e não há estudos sobre sua utilização em gestantes.   Na FMUSP há um equipamento 7T: o Magnetom 7T MRI é um equipamento de ultra-alto campo que oferece maior nível de sensibilidade e detalhamento para medidas estruturais e funcionais do organismo humano com ressonância magnética, tecnologia de diagnóstico por imagens que possibilita identificar propriedades de uma substância do corpo humano de modo não invasivo. As bobinas do aparelho interagem com os tecidos, em seu interior, utilizando ondas eletromagnéticas. Em seguida, são construidas as imagens, decodificando o sinal recebido dos átomos de hidrogênio da água que compõe o corpo humano. Tesla (homenagem a Nikola Tesla, inventor que fez grandes contribuições para a utilização da eletricidade e do magnetismo) é uma unidade de medida do campo magnético. A precisão das imagens geradas por um equipamento 7 Tesla, traduzida na resolução e na capacidade de discernir alterações, é mais de 5,4 vezes superior à de equipamentos 3 Tesla e 21 vezes superior à de aparelhos 1,5 Tesla utilizados em hospitais. Um aumento de duas vezes no campo magnético quadruplica a precisão das imagens.\nVantagens da MRI:\n Escaneamento de uma corte transversal cerebral em menos de 2 segundos, permitindo mapear a maior parte do cérebro em um ou dois minutos;\n Resoluções espaciais muito mais precisas de 2 a 3mm, conseguindo coletar informações em voxels (união volume com pixel) de aproximadamente o o tamanho de um grão de arroz;\n Não requer a utilização de contraste possibilitando um mapeamento mais extenso, e acaba com o receio de ingestão de materiais radioativos.\n  Desvantagens do MRI:\n Alguns estudiosos da área dizem que o aumento detectado no fluxo sanguíneo pode estar alimentando mais de uma operação, devido ao fato da ação neuronal levar milionésimos de segundos, enquanto o afluxo de sangue continua por dois a seis segundos;\n Um vez que cada voxel encerra milhares de neurônios, pode ser necessária a ativação de milhares ou mesmo milhões deles para acender uma região cerebral, é como se uma seção inteira de um estádio tivesse de gritar para ser ouvida;\n Em alguns casos um pequeno grupo de neurônios puxando pouco sangue, ou um circuito fino de neurônios conectado a regiões mais amplas, podem executar funções tão cruciais quanto um grupo maior, mas tanto passarem desapercebidos quanto serem identificados como uma função de menor importância;\n É possível que alguns neurônios funcionem melhor do que outros, e assim consumindo menos sangue, o que pode representar erroneamente a neurodinâmica real.\n    Leitura dos dados de MRI: Com esses equipamentos é possível extrair dados de MRI nas direções axial, coronal e sagital:\n O plano horizontal, transverso ou axialatravessa o eixo menor do corpo, do dorso até o ventre , isto é, da posição posterior para a anterior. Divide a estrutura atravessada em porções superior e inferior.\n Plano coronal ou plano frontal é um dos tipos de planos anatômicos, dividindo o corpo com cortes verticais e perpendiculares ao plano mediano. Assim é possível definir a parte ventral/anterior (frente) da parte dorsal/posterior (costas).\n O plano sagital mediano (ou plano mediano) divide o corpo em duas metades iguais, direita e esquerda. 2. Plano Frontal: são todos os planos verticais com trajeto paralelo à sutura coronal do crânio (ou da “testa”). O plano coronal divide o corpo em duas metades diferentes, anterior e posterior.\n  Para ler os arquivos nift e analyze, precisamos utilizar a biblioteca “AnalyzeFMRI”.\n#Instalar biblioteca para ler arquivos nifti e analyze #install.packages(\u0026quot;AnalyzeFMRI\u0026quot;) #Carrega biblioteca require(AnalyzeFMRI) #leitura da imagem no arquivo nifti volume = f.read.volume(\u0026quot;ch2.nii\u0026quot;) # Verificar a dimensão dos dados dim(volume) ## [1] 181 217 181 1 Fazer figuras desta imagem de ressonância, identificamos pelo eixo X, Y e Z e fixamos conforme a referência que queremos (sagital, coronal, axial)\n# Imagem AXIAL na secção z= 90, deixando x e y livres: # as.data.frame exibe menos poluido. volume[,,90,1] image(volume[,,90,1]) Alterando para uma escala de cinza:\nimage(volume[,,90,1], col = gray((1:50)/50)) (é possível verificar o caldado, ventrículo, giro fusiforme)\nPara visualizar no ângulo sagital:\n#Imagem SAGITAL na fatia x=100, deixo o y e z livres image(volume[100,,,1],col=gray((1:50)/50)) Para visualizar no coronal:\n#Imagem Coronal na fatia y=100 image(volume[,100,,1], col = gray((1:50)/50)) Nota: Não é possível identificar facilmente se o lado é esquerdo ou direito. Depende se a notação da imagem coletada é radiológica ou neurológica.\nOlhando as coordenadas em voxel (o parâmetro pode ter o primeiro argumento como um intervalo, depende da análise).\n#Colocar zero nas coordenadas x=100,y=100,z=150 (voxels) volume[100,100,150,1]=0  "
},
{
	"uri": "/aulas/8_fmri/",
	"title": "fMRI",
	"tags": [],
	"description": "",
	"content": "A imagem por ressonância magnética funcional (fMRI, do inglês Functional Magnetic Ressonance Imaging), é uma técnica específica do uso da imagem por ressonância magnética (MRI, do inglês Magnetic Resonance Imaging) capaz de detectar variações no fluxo sanguíneo em resposta à atividade neural. A fMRI tem dominado o cenário do mapeamento cerebral em parte devido ao fato de não utilizar radiação ionizante ou contraste exógeno. Além disso, essa técnica possui boa resolução espacial, embora a resolução temporal seja baixa em relação a outras técnicas, como EEG e NIRS.\nAs mudanças cardiovasculares cerebrais estão relacionadas à atividade elétrica neuronal, devido ao aumento do consumo de oxigênio. O Oxigênio é carregado pela hemoglobina. A hemoglobina desoxigenada (deoxi-Hb) é paramagnética ao passo que a hemoglobina oxigenada (Hb) é diamagnética. Desse modo, a mudança na proporção de Hb/deoxi-Hb durante o aumento de fluxo sanguíneo oxigenado leva a um pequeno aumento do sinal de ressonância subjacente ao local onde ouve aumento da atividade de neurônios. Esse mecanismo é a base do contraste utilizado na maioria dos experimentos de fMRI, e é conhecido como contraste BOLD (do inglês, Blood Oxygenation Level Dependent).\nJá em 1936, os químicos Linus Pauling e Charles Coryell mostraram que a hemoglobina possui diferentes momentos magnéticos, dependendo de como seus grupos Hemes estão ligados ao O2. Já em 1990, Seiji Ogawa reconheceu que essa diferença poderia ser usada em MRI para servir de contraste.\nEM 1989: Hipotese de Roy \u0026amp; Sherrington: Aumento da atividade metabólica local, por questões de manutenção da homeostase, é seguido de um aumento de fluxo sanguíneo para esta região.\nEm um estudo pioneiro, em 1990, Ogawa e colegas avaliaram roedores com um equipamento de MRI de alto campo magnético (7.0 T) e investigaram a hipótese de que a manipulação da proporção os níveis de O2 e CO2 no sangue alteraria o contraste em imagens ponderadas T2*. Eles mostraram redução do sinal próximo a vasos ricos em dHb, que era revertido pelo aumento do fluxo sanguíneo oxigenado através da manipulação da quantidade de gás inalado.\nO cérebro é incapaz de armazenar glicose, embora esse seja o único substrato que ele consome. Maior fluxo sanguíneo significa maior disponibilidade de glicose e oxigênio, na forma de hemoglobina oxigenada, em parte devido à dilatação local dos vasos sanguíneos. O aumento do fluxo sanguíneo também acompanha o aumento da atividade elétrica de neurônios. Comumente o aumento do fluxo de oxigênio é maior que o oxigênio consumido na queima de glicose, o que causa a diminuição de dHb nesses vasos sanguíneos. Essas mudanças nas propriedades magnéticas do sangue, fazem com que as áreas ativas interfiram menos na magnetização transversa e no eventual decaimento de T2* induzido por deformação magnética espacial, levando a um leve aumento do sinal de MRI\nO parâmetro básico para a resolução temporal é o Tempo de repetição ou TR, que representa o quão frequentemente uma determinada fatia do cérebro é excitada por um pulso RF e decaí ao ponto inicial,, o que no sinal será observado por sua perda de magnetização relativa a T2. TRs podem variar de muito curtos (500 ms) até muito longos (3 s). Especificamente para o fMRI, a resposta hemodinâmica dura em torno de 10 segundos, aumentando multiplicadamente (sempre proporcional ao valor original), atingindo o ápice de 4 a 6 segundos, e então caindo da mesma maneira. Mudanças no fluxo sanguíneo ocorrem via mudanças no sistema vascular concomitantes a atividade neuronal ao longo do tempo. Por essas resposta serem contínuas e suaves, fazer uma amostragem com TRs mais rápidos não iria ajudar. Apenas aumentariam o número de pontos na curva obtidos por uma simples interpolação linear mais não adicionaria informação relevantes aos dados. Paradigmas experimentais tais como um escalonamento quando ocorre a apresentação do estímulo em várias séries de testes podem ajudar a melhorar a resolução temporal, mas reduz o número efetivo de dados pontuais obtidos.\nA mudança no sinal MR causado pela atividade neuronal é chamada de resposta hemodinâmica (HDR do inglês Hemodynamic response). O HDR possui um atraso em relação a atividade neuronal entre 1 e 2 segundos, visto que o sistema vascular leva esse tempo para responder a necessidade cerebral de glicose. O pico do sinal da MR normalmente ocorre 5 segundos após o estimulo. Se os neurônios continuarem disparando, o que é chamado de estímulo contínuo, o pico se espalha para um platô enquanto os neurônios se mantiverem ativos. Depois que a atividade cessa, o sinal BOLD cai para os valores originais, os níveis basais, ou podem cair ainda mais em um fenômeno chamado undershoot (supra limiar). A resposta de um único voxel ao longo do tempo representa seu curso temporal. O sinal pode vir de maneira indesejada o que é chamado de ruído e normalmente advém do próprio aparelho de ressonância magnética, da atividade cerebral espontânea, e pode ser tão forte quanto o sinal em si. Para eliminar o ruído estudos que fazem uso do fMRI repetem o estimulo múltiplas vezes para calcular uma média.\nBrain Extraction Tool O algoritmo BET elimina o tecido não cerebral a partir de uma imagem de toda a cabeça. Ele também pode estimar as superfícies interna e externa do crânio e a superfície externa do couro cabeludo, no caso de imagens de entrada T1 e T2 de boa qualidade.\n Processamento dos dados e tratamento Para o tratamento e processamento das imagens, pode-se separar nos seguintes passos:\n Suavização espacial (spatial smoothing): borrar a imagem. Muitas vezes, quando trabalhamos com imagens distintas, temos cérebros com formatos distintos. Para padronizar esses dados, utilizamos métodos de deformação de imagem para adição a um modelo padrão. Um modelo comum é o MNI152, deformando para um template, o que chamamos de normalização espacial. Como essa normalização nunca é perfeita, ainda sobram alguns voxels que não ficam perfeitamente alinhados.\n normalização espacial\n segmentação: separa entre o que for substância branca, substância cinzenta e liquor.\n Voxel based morphometry VBM: Baseado nas três etapas e com análise de inferência bayesiana: Para cada voxel, estima a prob (%) de ser substância branca, cinzenta, liquor, etc…\n  No geral, analisamos mais substância cinzenta no VBM.\nJohn Ashburner indicou que não querem verificar a probabilidade mas sim a redução modulando a deformação e tendo uma estimativa de volume. A VBM é portanto uma medida de diferenças estruturais ou anatómicas entre um grupo de controle clínico e saudável. O VBM permite a análise da concentração de tecido numa base de voxel por voxel. A este respeito, a VBM difere de outras medidas de morfometria que use uma abordagem de região de interesse (ROI). Os dados de VBM são normalizados e mapeados para um modelo cerebral que reduz o impacto das diferenças individuais na anatomia do cérebro. Medidas VBM mostraram diferenças na concentração de substância cinzenta nos lobos temporal e frontal em pacientes com esquizofrenia e controles saudáveis.\nNa sua forma mais simples, a morfometria baseada em voxel (VBM) envolve uma comparação voxel-wise (não sei como traduzir) da concentração local de substância cinzenta entre dois grupos de indivíduos. O procedimento envolve a normalização espacial de imagens de alta resolução de todos os participantes do estudo no mesmo espaço estereotáxico. Segue-se a segmentação da massa cinzenta a partir das imagens espacialmente normalizadas e suavização dos segmentos de matéria cinzenta. Testes estatísticos paramétricos de voxel que comparam as imagens de substância cinzenta suavizadas dos dois grupos são realizados. Em seguida, são aplicadas as correções para comparações múltiplas feitas usando a teoria dos campos aleatórios de Gauss. Ashburner, descreve os passos envolvidos no VBM, enfatizando a segmentação da massa cinzenta a partir de imagens RM com artefato não uniformizado e fornecendo avaliações das premissas que sustentam o método, incluindo a precisão da segmentação e as suposições feitas sobre a distribuição estatística dos dados.\nA morfometria baseada em deformação e baseada em tensores em referência a métodos para estudar formas cerebrais baseadas em campos de deformação obtidos por registro não-linear de imagens cerebrais. Quando comparamos grupos, a morfometria baseada em deformação (DBM) usa campos de deformação para identificar diferenças nas posições relativas de estruturas dentro dos cérebros dos sujeitos, enquanto usamos o termo morfometria baseada em tensores para nos referirmos àqueles métodos que localizam diferenças na forma local de estruturas cerebrais.\nExplicação do Jacobiano do modelo da imagem: Efeito da modulação de imagens segmentadas. O determinante Jacobiano representa as mudanças de volume devido à normalização espacial não linear. Essas alterações de volume são usadas para modular o resultado da segmentação.\nO VBM segmenta a imagem entre massa cinzenta, branca e fluído espinal, adequando as imagens para um template e suavizando-as. A análise estatística é baseada no General Linear Model (GLM). O modelo básico constitui na normalização, segmentaçãoe suavização.\nEx: GM-modulated (massa cinzenta modulada)…é o VBM com a modulação pelo jacobiano\nCom grupos de indivíduos, tem-se grupos de voxel em vários grupos para cada voxel para identificar a intensidade do GM-modulated em múltiplos indivíduos (normalmente fazem um teste T). Muitos estudos se apoiam no VBM, mas conforme avançam as pesquisas de computação, a modelagem do córtex vem como uma superfície cortical ao invés da massa cinzenta.\nNo entanto, essa aplicação pode ser demorada e só pode fornecer medidas de áreas bastante amplas. Diferenças menores no volume podem ser negligenciadas uma vez que o VBM registra cada cérebro para um modelo, o que implica em se livrar da maioria das grandes diferenças na anatomia do cérebro entre as pessoas. Então as imagens cerebrais são suavizadas para que cada voxel represente a média de si mesmo e seus vizinhos. Finalmente, o volume da imagem é comparado entre os cérebros em cada voxel.\nÉ importante o cuidado na suavização pois o VBM pode ser sensível a vários artefatos, que incluem desalinhamento das estruturas cerebrais, classificação errônea dos tipos de tecido, diferenças nos padrões de dobra e na espessura cortical. Todos estes erros de classificação podem confundir a análise estatística e diminuir a sensibilidade de verdadeiros efeitos volumétricos ou aumentar a chance de falsos positivos. Para o córtex cerebral, foi demonstrado que as diferenças de volume identificadas com a VBM podem refletir principalmente diferenças na área de superfície do córtex, do que na espessura cortical.\n No SPM: Entre os desenvolvimentos que despertam interesse estão os métodos de análise automática de imagens, que permitem a quantificação de anormalidades em exames radiológicos no nível do voxel (a unidade tridimensional básica das imagens cerebrais, de volumes na ordem de poucos milímetros cúbicos). O método de análise voxel-a-voxel mais conhecido é o Statistical Parametric Mapping (SPM). O plugin SPM para o MATLAB executa diversas etapas no processamento de imagens de RM. Deformação não linear: cada região da imagem ele faz um mapeamento para o template.\nNo SPM aplica-se algoritmo para smooth a imagem, a convolução basicamente faz uma média ponderada dos vizinhos de cada conjunto de voxels.\n Bases físicas, neurológicas e pré-processamento O tecido pode ser caracterizado por dois tempos diferentes de relaxamento - T1 e T2. No T1 (tempo de relaxamento longitudinal) é a constante de tempo que determina a taxa na qual os prótons excitados retornam ao equilíbrio. É uma medida do tempo gasto para girar prótons para realinharem-se com o campo magnético externo. T2 (tempo de relaxamento transverso) é a constante de tempo que determina a taxa na qual os prótons excitados atingem o equilíbrio ou saem de fase um com o outro. É uma medida do tempo necessário para os prótons girarem e perderem a coerência de fase entre os núcleos girando perpendicularmente ao campo principal.\nPara ver estruturas cerebrais, utilizamos: * T1 * T2 * Flair * DWI\nO EPI T2*: uma variação para aquisição de dados fMRI. Configuração de dados de forma extremamente sensível.\nObs: DTI para ver tratos/tractografia ou outras análises\n Resolução fMRI e comparação: No caso de fMRI, a coleta está em torno de 1-3s, em geral coleta-se a cada 2s. A tava de amostragem então é a cada 0,5hz, o que é muito mais lento que outras técnicas como EEG, NIRS etc. A resolução temporal é muito inferior ao EEG mas a resolução espacial é melhor que o EEG.\nEm ressonância, denominamos por TR o tempo de repetição (tempo entre as imagens da coleta).\nOs métodos mais acessíveis, como a tomografia computadorizada (TC), a ressonância magnética (RM) e a tomografia computadorizada por emissão de fóton único (single photon emission computed tomography - SPECT) são recursos importantes para o diagnóstico diferencial de demências; para o diagnóstico e manejo de doenças neurológicas que comumente cursam com sintomas psiquiátricos. No caso, SPECT e PET possuem maior resolução temporal e espacial que fMRI:\nEmbora a ressonância magnética funcional (fMRI) tenha algumas vantagens sobre PET e SPECT, devido às suas características de melhor resolução espacial e, principalmente, temporal, não-invasiva (sem uso de radiação ionizante), que permite múltiplas seqüências/estudos do mesmo indivíduo na mesma sessão, os modelos para quantificação de informação e a capacidade de estudar uma gama muito maior de funções cerebrais, que incluem principalmente a neurotransmissão e os neurorreceptores, são específicos da tomografia de emissão (PET e SPECT)\n Processo de acoplamento hemodinâmico (medida indireta):  Aumento da atividade neuronal local Dilatação das arteríolas Aumento do fluxo sanguíneo Diminuição da concentração de desoxihemoglobina Aumento da sinal BOLD por conseguinte   Pré-processamento das imagens: Fases do pré-processamento:\nSlice-timing correction: Faz interpolação para virtualmente alinhar todas as fatias para o mesmo ponto no tempo para ficar na mesma referência. Maior parte dos programas utiliza método da translação de fase (coleta ascendente, descendente, intercalado)\n Correção de movimento/Motion Correction: Ou também images realignment. Translação de corpo rígido. Temos três parâmetros de translação (base X, Y, Z), e três parâmetros de rotação. Por isso chamamos de translação de 6 parâmetros.\n Filtros/detrend: Para cada voxel, é aplicado um filtro temporal ao sinal correspondente. Esse filtro em geral pode ser separado em dois tipos (pode variar conforme taxa de amostragem). Se o interesse é obter mapas de ativação, em geral se utiliza um filtro passa-alta. O sinal da ressonância também é sensível a temperatura (não só desoxi). Conforme a máquina funciona e esquenta, queremos eliminar os artefatos de baixa-frequência.\n  Para análise de conectividade funcional, utiliza-se passa-banda\nOutro filtro comum é o detrend: O sinal bold pode estar caindo com o tempo e para isso é aplicado o filtro: aplicando regressão linear menos o predito (linear), é possível ajustar também fazer um quadrático (parábola), já também foi aplicado cúbico na tentativa de limpar os ruídos. Geralmente também pode ser de baixa frequência.\nSpatial normalization: Colocar no template específico para todos os sujeitos. Trabalhar com grupos de indivíduos.\n Spatial smoothing: Corrigir alguns voxels que não foram bem encaixados e manter as propriedades estatísticas. “Borrar”\n  Leitura dos dados:\n#Carrega a biblioteca require(AnalyzeFMRI) ## Carregando pacotes exigidos: AnalyzeFMRI ## Carregando pacotes exigidos: R.matlab ## R.matlab v3.6.1 (2016-10-19) successfully loaded. See ?R.matlab for help. ## ## Attaching package: \u0026#39;R.matlab\u0026#39; ## The following objects are masked from \u0026#39;package:base\u0026#39;: ## ## getOption, isOpen ## Carregando pacotes exigidos: fastICA ## Carregando pacotes exigidos: tcltk ## Carregando pacotes exigidos: tkrplot #Leitura dos dados volumes=f.read.volume(\u0026quot;Stroop.nii\u0026quot;) #Checar as dimensoes da imagem dim(volumes) ## [1] 45 54 45 180 #Plotar uma imagem axial do primeiro volume image(volumes[,,25,1],col=gray((0:100)/100)) Verificar em todos os pontos do tempo:\n#Plotar o sinal BOLD da imagem preprocessada #no voxel=x=20,y=30,z=25 ts.plot(volumes[20,30,25,]) Para marcar a posição do voxel:\nvolumes[20,30,25,]=0 image(volumes[,,25,1], col=gray((0:100)/100)) dim(volumes) ## [1] 45 54 45 180  "
},
{
	"uri": "/aulas/9_glm/",
	"title": "GLM - Modelo Linear Geral",
	"tags": [],
	"description": "",
	"content": "Na ressonância magnética funcional, a hemoglobina que carrega o oxigênio é chamada oxiemoglobina (oxyHb) e ao se desprender do oxigênio essa passa ser chamada desoxihemoglobina (deoxyHb). A oxyHb possui propriedade diamagnética, isto é fraca interação com outros campos magnéticos; tem momento magnético zero e nenhum elétron sem par. Já a deoxyHb é paramagnética, isto é possui maior susceptibilidade magnética, com elétrons não pareados e momento magnético significativo. Assim, na presença de um campo magnético intenso, como da ressonancia, as moleculas de deoxyHb causam uma atenuação do campo magnético e consequentemente uma alteração no contraste da imagem. Como resultado deste comportamento, tem-se o chamado sinal BOLD (Blood Oxigenated level dependent) que é medido pela ressonância magnética funcional (fMRI) - Notas de aula da Cândida.\nO sinal BOLD medido na fMRI está relacionado com a variação da quantidade de deoxyHb na região de estudo. O aumento da atividade cerebral, aumenta o fluxo sanguíneo para aquela região como uma forma de suprir a demanda metabólica. As células que cuidam da estrutura cerebral são as Glias, os astrocitos (metabolismo) e os oligocitrocitos (estrutural). A presença dos oligocitrocitos causam um aumento do vasos sanguíneos, que causa o aumento do fluxo sanguíneo e consequentemente diminuição da deoxyHb e aumento da oxyHb causando um aumento no sinal BOLD, isso é chamado de acoplamento hemodinâmico. Graças ao acoplamento hemodinâmico podemos medir o sinal BOLD e associa-lo a atividade cerebral, possibilitando a realização de inferências sobre o comportamento do cérebro.\nO método GLM – Modelo Linear Geral é um método estatístico utilizado para verificar como uma variável depende de outras variáveis de interesse. Neste modelo a variável dependente é escrita como uma combinação linear das variáveis independentes, onde os coeficientes dessa combinação representam. A regressão linear é utilizada em umas das análises feitas com dados de fMRI, que são os mapas de ativação. Esses mapas mostram as regiões ativadas, de indivíduos ou grupo de indivíduos, quando estão realizando alguma tarefa cognitiva.\nA regressão é dada por: \\[ \\begin{align} y = \\beta xi + \\alpha + \\epsilon_1 \\end{align} \\] Estimador de mínimos quadrados pelo pela contrução das matrizes:\n\\[\\begin{align} Y = \\begin{bmatrix} \\\\ y_1 \\\\ y_2 \\\\ y_3 \\\\ ... \\\\ y_n \\end{bmatrix} \\end{align}\\] e:\n\\[\\begin{align} X = \\begin{bmatrix} \\\\ 1 \u0026amp;\u0026amp; x_1 \\\\ 1 \u0026amp;\u0026amp; x_2 \\\\ 1 \u0026amp;\u0026amp; x_3 \\\\ ... \\\\ 1 \u0026amp;\u0026amp; x_n \\end{bmatrix} \\end{align}\\] Para conseguir entender melhor como gerar esses mapas de ativação, abaixo segue uma melhor compreensão do modelo. Primeiro implementaremos manualmente e na sequência com o modelo já do próprio R:\nSimulando um modelo linear:\n# Neste caso, y não depende de x: X = rnorm(100) Erro = rnorm(100) Y = 2 + 0*X + Erro plot(X, Y) Estimadores de MMQ para alfa e beta:\n# Cria o vetor Ytil (vertical) e a matriz Xmat (design matrix) N = 100 #arbitrario Ytil = matrix(Y, N, 1) # já atribuindo Xmat = matrix(1, N, 2) Xmat[ ,2] = X # Faz os cálculos na multiplicação matricial betahat = solve(t(Xmat)%*%Xmat)%*%t(Xmat)%*%Ytil # estimador é a fórmula que traz a estimativa. Ypredito = betahat[1]+ betahat[2]*X plot(X, Y) lines(X, Ypredito, col=2) # Estimativa dos erros (resíduos) residuos = Y-Ypredito plot(X, Y) plot(X, residuos) Modelo de regressão linear múltipla:\nObjetivo: Prever o valor de Y utilizando múltiplas variáveis. Fazendo um exemplo com 3:\n\\[ Y_i = \\alpha + \\beta_1 * X_i + \\beta_2*Wi + \\beta_3*Zi + \\epsilon_i \\]\nNeste caso, quero achar os betas que melhor se ajustam ao que estou querendo modelar. Note que é uma função linear, quero saber quais são os pesos que me ajudam a ter uma melhor predição.\nEstimadores de Mínimos quadrados:\n\\[\\begin{align} Y = \\begin{bmatrix} \\\\ y_1 \\\\ y_2 \\\\ y_3 \\\\ ... \\\\ y_n \\end{bmatrix} \\end{align}\\] Supondo um exemplo de regressão múltipla com 3 variáveis:\n\\[\\begin{align} X = \\begin{bmatrix} \\alpha \u0026amp;\u0026amp; \\beta_1 \u0026amp;\u0026amp; \\beta_2 \u0026amp;\u0026amp; \\beta_3 \\\\ 1 \u0026amp;\u0026amp; x_1 \u0026amp;\u0026amp; y_1 \u0026amp;\u0026amp; z_1 \\\\ 1 \u0026amp;\u0026amp; x_2 \u0026amp;\u0026amp; y_2 \u0026amp;\u0026amp; z_2 \\\\ 1 \u0026amp;\u0026amp; x_3 \u0026amp;\u0026amp; y_3 \u0026amp;\u0026amp; z_3 \\\\ ... \u0026amp;\u0026amp; ... \u0026amp;\u0026amp; ... \u0026amp;\u0026amp; ... \\\\ 1 \u0026amp;\u0026amp; x_n \u0026amp;\u0026amp; y_n \u0026amp;\u0026amp; z_n \\end{bmatrix} \\end{align}\\] Estimando \\(beta\\):\n\\[\\begin{align} \\hat{\\beta} = (X´ X)^{-1} X´ Y = \\begin{bmatrix} \\\\ \\alpha \\\\ \\beta_1 \\\\ \\beta_2 \\\\ \\beta_3 \\end{bmatrix} \\end{align}\\] N=100 #Simular um modelo linear X=rnorm(N) Z=rnorm(N) W=rnorm(N) Erro=rnorm(N) Y= 3 + 5*X + 0*W -2*Z + Erro #Estimadores de Minimos quadrados para alfa e beta1, beta2 e beta3 #Cria o vetor Ytil (em pe) e a matriz Xmat (Design Matrix) Ytil=matrix(Y,N,1) Xmat=matrix(1,N,4) Xmat[,2]=X Xmat[,3]=W Xmat[,4]=Z #Faz os calculos betahat= solve(t(Xmat)%*%Xmat)%*%t(Xmat)%*%Ytil #Estimativa dos erros (residuos) residuos=Y-Ypredito No R, utlizamos a função lm para implementação do modelo. Neste caso, explicando Y em função das variáveis independentes X, W e Z:\nmodelo = lm(Y~X+W+Z) Se comparar os resultados deste com o que foi feito manualmente acima, pode verificar que é idêntico ao que foi calculado manualmente:\nsummary(modelo) ## ## Call: ## lm(formula = Y ~ X + W + Z) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.85988 -0.67135 0.06011 0.59389 2.23568 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 3.09665 0.09150 33.84 \u0026lt;2e-16 *** ## X 4.78476 0.09495 50.39 \u0026lt;2e-16 *** ## W -0.02533 0.09736 -0.26 0.795 ## Z -1.88416 0.09021 -20.89 \u0026lt;2e-16 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 0.9051 on 96 degrees of freedom ## Multiple R-squared: 0.9704, Adjusted R-squared: 0.9695 ## F-statistic: 1048 on 3 and 96 DF, p-value: \u0026lt; 2.2e-16 Olhando a tabela de resultados,\n Estimate = mesmos valores estimados antes Std Error: desvio padrão do estimador t valor: o valor de t (veremos posteriormente) Pr(\u0026gt;|t|): neste modelo se o p-valor for menor que 5%, temos evidências que este valor é estatisticamente diferente de zero  Olhando o resultado do W, você consegue verificar que o valor-p é muito maior, o que de fato, pela nossa construção é possível verificar.\n R2 ajustado corrige pelo número de variáveis que estão sendo utilizadas R não ajustado considera todas as variáveis que estão entrando  Modelo polinomial de ordem 3 X = rnorm(100) Erro = rnorm(100) Seja o polinômio de ordem três: Y = 2 + 3X +0.5X^2 + 0.1*X^3 + Erro\nplot(X, Y) Y=2 + 3*X + 1*X^2 + 0.1* X^3 plot(X, Y) modelo = lm(Y~X) lines(X, modelo$fit, col = 2) Neste caso é possível verificar que um modelo linear não se adequa diretamente bem, pois trata-se de uma curva. Passamos então a construir com mais variáveis.\nAplicando a regressão lm prevendo Y usando X, W e Z:\n# termo quadrático W = X^2 # termo cúbico: Z = X^3 Ypredito = modelo$fit Se colocar esse modelo para visualização, podemos ver a seguinte bagunça:\nplot(X, Y) lines(X, Ypredito, col=2) Isso acontece porque ele liga todos os pontos na ordem em que é gerado, o que não é adequado para esse novo modelo. Por isso utilizamos o points:\nplot(X, Y) points(X, Ypredito, col=2) Na próxima aula, veremos mapas probabilísticos para estimar os mapas de ativação do bold. Também é válido para o NIRs.\n "
},
{
	"uri": "/aulas/10_fmri_design_mapas/",
	"title": "Mapas de ativação e testes para fMRI",
	"tags": [],
	"description": "",
	"content": "Para esse exercício, vamos utilizar dados de uma tarefa do tipo stroop. Essa tarefa consiste na medida do tempo de reação e na acurácia da leitura, em voz alta, de palavras em duas situações: 1. As palavras estão escritas na mesma cor que a cor expressa pelo significado semântico - denominamos por CONGRUENTES 2. As palavras estão numa cor que difere da cor expressa pelo significado semântico (exemplo: a palavra vermelho impressa com tinta azul) - denominamos por INCONGRUENTES\nEstima-se que na segunda situação ocorre um atraso no processamento da cor da palavra, induzido pelo conflito no processamento da informação e por conseguinte, causando tempos de reação mais lentos e um aumento de erros.\nQuando se trata de experimentos, o maior erro dos novatos é acreditar que com um estímulo só é possível comparar repouso com o estímulo. É necessário ter uma amostra representativa para conseguir garantir os dados para comparação.\nPara análise, seguiremos os seguintes passos:\nDefinição do block design do experimento Coleta de dados Pré-processamento do sinal: Correção do motion correction (quando a pessoa se mexe durante a aquisição de dados. Nesse caso é feito o realinhamento, com corpo rígido: 3 parâmetros rotação, 3 parâmetros de translação e/ou combinações desses movimentos). Especificar a convolução da HRF - hemodynamic response function (veremos adiante) Aplicação do GLM no sinal BOLD para cada voxel x.y.z, usando como variável preditora os dados de convoluídos Aplicação de um teste estatístico para definir quais voxels são relevantes para construção dos mapas Visualização e armazenamento dos mapas  A ideia aqui é investigar a ativação cerebral para cada uma das situações: CONGRUENTES e INCONGRUENTES. Então, primeiramente realizamos a leitura dos dados:\n# Imagem esta preprocessada # SPM (UCL) e FSL (Oxford) require(AnalyzeFMRI) #Leitura de dados de fMRI volume=f.read.volume(\u0026quot;Stroop.nii\u0026quot;) #Leitura das condicoes (desenho experimental) congruente=scan(\u0026quot;congruent.txt\u0026quot;) incongruente=scan(\u0026quot;incongruent.txt\u0026quot;) Obs: O comando scan é melhor (mais rápido) para ler vetor do que o read.table, mais usado para ler .txt\nA função resposta ao estimulo congruente (ativação durante o estimulo, CONG = 1; e não ativação, fora do estímulo CONG = 0), como se observa em:\nts.plot(congruente) O objetivo da análise é estimar se, e em que medida, cada preditor contribui para a variabilidade observada no curso do tempo do voxel. Considere, por exemplo, uma experiência na qual a resposta BOLD, \\(y\\), é amostrada \\(n\\) vezes (ou seja, volumes). A intensidade do sinal BOLD em cada observação (\\(y_i\\)) pode ser modelada como a soma de um número de variáveis preditoras conhecidas (\\(x_1,… x_p\\)), cada uma escalonada por um parâmetro (\\(\\beta\\)):\nRealizemos agora a convolução dos estímulos sobre a resposta hemodinâmica esperada do indivíduo. Ou seja, ao ser submetido ao estimulo, espera-se que ocorra uma ativação cerebral associada a essa resposta. Essa ativação chamada de função resposta hemodinâmica (HRF – hemodinamic response functional).\nA equação abaixo mostra a convolução da função resposta pela HRF pela HRF do modelo de Garry Glover:\n\\[ \\begin{align} X[t] = \\sum_{l=0}^{k} HRF[k] \\hspace{1mm}* C[t-k] \u0026amp;\u0026amp; \\text{(sendo C a condição)} \\end{align} \\]\nEm código, essa função dada pelo modelo de Garry Glover faz duas curvas gaussianas e a HRF é a combinação linear dessas duas gaussianas. Os parâmetros já seguem por default:\nglover=function(HZ){ a1=6 a2=12 b1=0.9 b2=0.9 d1=5.4 d2=10.8 c=0.35 x=seq(0, 30, 1/HZ) # HZ is the Sampling Rate (Heartz) glover1=((x/d1)^a1)*exp((-x+d1)/b1) glover2=((x/d2)^a2)*exp((-x+d2)/b2) G=glover1-c*glover2 return(G) } Determinando HRF: Função de resposta hemodinâmica, considerando um tempo de repetição TR de 2s, ou seja 1/2:\n#HRF- Funcao de resposta hemodinamica HRF = glover(0.5) Exemplo de event-related (similar ao potencial evocado, vários experimentos coletados coincidindo). No caso de estímulos muito consecutivos, a curva basal nem retorna ao original, o que dificulta na visualização:\nCONDICAO = array(0, 90) CONDICAO[30] = 1 CONDICAO[60] = 1 ts.plot(CONDICAO) # Convolucao do vetor condicao pela HRF # ATENCAO: NAO LER o pacote signal, pois a função # que faz a convolução tem o mesmo nome da que faz a # filtragem em frequência X = filter(CONDICAO, HRF, sides=1, method=\u0026quot;convolution\u0026quot;) ts.plot(cbind(CONDICAO, X), col = c(1,2)) Exemplo de Desenho block-design:\nCONDICAO = array(0, 90) CONDICAO[20:40] = 1 CONDICAO[60:80] = 1 X = filter(CONDICAO, HRF, sides=1, method=\u0026quot;convolution\u0026quot;) ts.plot(cbind(CONDICAO, X), col=c(1, 2)) Identificando a convolução das condições pela HRF:\n#Convolucao da condicao congruente pela HRF X=filter(congruente, HRF, sides=1, method=\u0026quot;convolution\u0026quot;) #Convolucao da condicao incongruente pela HRF Z=filter(incongruente, HRF, sides=1, method=\u0026quot;convolution\u0026quot;) Ao plotarmos a função que representa um modelo de ativação relacionado ao design do experimento, verificamos comportamentos semelhantes. Analisando as duas condições:\nts.plot(cbind(congruente, incongruente), col=c(1,2)) ts.plot(cbind(X, Z), col=c(1, 2)) A título de curiosidade, essa convolução utilizada na função filter é equivalente ao seguinte código (as saídas são equivalentes):\n#Faça a convolução do INCONG pela HRF. Z = array(0,length(incongruente)) for(ti in (length(HRF)+1):length(incongruente)){ for( i in 1:length(HRF)){ Z[ti]= Z[ti]+ incongruente[ti-i]*HRF[i] } } #Convolução do CONG pela HRF X = array(0,length(congruente)) for(ti in (length(HRF)+1):length(congruente)){ for( i in 1:length(HRF)){ X[ti]= X[ti]+ congruente[ti-i]*HRF[i] } } #Normalizando (colocar o máximo em 1) os dados da condição para facilitar a interpretação. X = X/max(X) Z=Z/max(Z) Para garantir uma resposta hemodinâmica mais próxima do que se espera é feita uma convolução da resposta esperada relacionada ao desenho do experimento com a função resposta hemodinâmica do modelo de Garry Glover, dando origem a um sinal convoluído que representa como seria, idealmente, o comportamento do sinal BOLD para aquele modelo de experimento.\nRealizando o ajuste do modelo linear geral:\nNo GLM, faremos uma regressão linear múltipla onde o Y é o sinal BOLD, usando a HRF convoluída. No fundo, quero saber se o sinal se comporta conforme a ativação do voxel (se o voxel é ativado por um determinado estímulo). Para cada voxel x, y e z vamos rodar o GLM (Regressao multipla) usando como variável preditora os dados dessa convolução.\nPara regressão múltipla, faremos um ajuste de nível (\\(\\alpha\\)) e de escala (\\(\\beta\\))\n\\[ \\begin{align} BOLD_{x,y,z}[t] = \\alpha + \\beta . X_t + \\epsilon_t \u0026amp;\u0026amp; \\text{(sendo } X_t \\text{ a condição da convolução)} \\end{align} \\]\nneste caso, supondo: \\(\\epsilon_t\\) com média zero e variância constante (homocedasticidade) e os erros \\(\\epsilon_t\\) são independentes\nPara comparação, faremos um teste de hipóteses. Analisando pelo t-valor, estatística t (verificar ativa ou não e se é estatisticamente diferente de zero ou não): Estatística T do beta correspondente a condição congruente é igual ao do modelo.\nObs: O valor p não armazena sinal, ou seja, não conseguimos verificar existência de ativação ou de desativação.\nFazendo os Mapas de estatisticas T:\n# Verificando a dimensão do volume para identificar como serão os mapas: dim(volume) ## [1] 45 54 45 180 Considerando no caso do GLM o \\(\\beta_1\\) o congruente e \\(\\beta_2\\) o incongruente:\n# Considera as dimensões da matriz volume e adiciona esse 1, para construção do mapa mapaTcongruente = array(0,c(45,54,45,1)) mapaTincongruente = array(0,c(45,54,45,1)) for(xi in 1:45){ for(yi in 1:54){ for(zi in 1:45){ #pega somente os voxels intracranianos, ou seja, diferentes de zero: if(volume[xi,yi,zi,1]!=0){ #Ajuste do modelo linear geral - GLM: modelo=lm(volume[xi,yi,zi,]~X+Z) #Estatistica T do beta correspondente a condicao congruente mapaTcongruente[xi,yi,zi,1] = summary(modelo)$coef[2,3] # Beta_1 #Estatistica T do beta correspondente a condicao incongruente mapaTincongruente[xi,yi,zi,1] = summary(modelo)$coef[3,3] #Beta_2 }#fecha if }}}#fecha for do xi,yi,zi Se quero testar se \\(beta_1\\) \u0026gt; 0, ou seja ativação de congruente vs nêutro: \\[ \\begin{align} \\begin{bmatrix} \\\\ 1 \u0026amp;\u0026amp; 0 \u0026amp;\u0026amp; 0 \\end{bmatrix} \\end{align} \\]\nSe quero testar se \\(beta_1\\) \u0026lt; 0, ou seja deativação de congruente vs nêutro: \\[ \\begin{align} \\begin{bmatrix} \\\\ -1 \u0026amp;\u0026amp; 0 \u0026amp;\u0026amp; 0 \\end{bmatrix} \\end{align} \\]\nSe quero testar se \\(beta_2\\) \u0026lt; 0: \\[ \\begin{align} \\begin{bmatrix} \\\\ 0 \u0026amp;\u0026amp; -1 \u0026amp;\u0026amp; 0 \\end{bmatrix} \\end{align} \\]\nE por fim, se quero testar a ativação Incongruente \u0026gt; Congruente, ou seja, \\(beta_2\\) \u0026gt; \\(beta_1\\), quero verificar se \\(-\\beta_1 + \\beta_2 \u0026gt; 0\\), logo, na condição:\n\\[ \\begin{align} \\begin{bmatrix} \\\\ -1 \u0026amp;\u0026amp; +1 \u0026amp;\u0026amp; 0 \\end{bmatrix} \\end{align} \\]\nA estatística T me diz se por exemplo os valores de \\(\\beta_1\\) são maiores ou não que zero. Usamos um p de 0,1% para evitar os ruídos da suavização, que geram falsos positivos (t = 3.03).\nAgora, armazenando os mapas em arquivos no formato Analyze (um IMG e um HDR):\nf.write.analyze(mapaTcongruente, \u0026quot;MapaCongruente\u0026quot;, pixdim = c(4, 4, 4), originator = c(23.5, 32.5, 19, 1, 1)) f.write.analyze(mapaTincongruente, \u0026quot;MapaIncongruente\u0026quot;, pixdim = c(4, 4, 4), originator = c(23.5, 32.5, 19, 1, 1)) Um artigo muito interessante que resume o uso de GLM nas análises de fMRI: https://doi.org/10.3389/fnhum.2011.00028\n"
},
{
	"uri": "/aulas/11_contraste/",
	"title": "Análise 1st e 2nd level",
	"tags": [],
	"description": "",
	"content": "Observações: Movimentação de corpo rígido:\n\\[ \\begin{align} BOLD_{t} = \\alpha + \\beta . X_t + (\\gamma_1\\mu_1 + ...+\\gamma_6 \\mu_6) + \\epsilon_t \u0026amp;\u0026amp; \\text{(sendo } X_t \\text{ a condição da convolução)} \\end{align} \\]\nNeste caso, \\(\\gamma_1\\mu_1 + ...+\\gamma_6 \\mu_6\\) é a combinação do ajuste de corpos rígidos para ajuste de movimento. São 6 eixos (3 de rotação e 3 de translação). São utilizados pois muitas coletas de fMRI são realizadas com movimento (fala, movimento da mão ou com alguma tarefa que pode gerar movimentação). Alguns pesquisadores sugerem 12 movimentos, que seriam os 6 usuais utilizados e suas derivadas para correção.\nEm event-related, além da condição convoluída pela HRF, inclui também suas derivadas.\nPara mapas de ativação de um indivíduo - 1st level Se quiser sofisticar a análise com mais acurácia, realizamos os ajustes:\n\\[ \\begin{align} BOLD_{t} = \\alpha + \\beta_1 . X_t + \\beta_2. X_t\u0026#39; + \\epsilon_t \u0026amp;\u0026amp; \\text{(sendo } X_t\u0026#39; = X_t - X_{t-1} \\text{)} \\end{align} \\]\nA adição de Kernels de Volterra:\n\\[ \\begin{align} BOLD_{t} = \\alpha + \\beta_1 . X_t + \\beta_2. V_t\u0026#39; + \\epsilon_t \u0026amp;\u0026amp; \\text{(sendo } V_t \\text{ os kernels de Volterra)} \\end{align} \\] E no caso dos testes estatísticos de ativação, trabalharia com o \\(\\beta_1\\)\nAlém disso, trabalha-se com a autocorrelação dos resíduos. Seja o modelo  \\[ \\begin{align} Y_{t} = \\alpha + \\beta . X_t + \\epsilon_t \\end{align} \\]\nneste caso, supondo: \\(\\epsilon_t\\) com média zero e variância constante (homocedasticidade) e os erros \\(\\epsilon_t\\) são independentes\n3.1 Pre-whitening: Aplicação de modelo autoregressivo 3.2 Estimação não-paramétrica e semi-paramétrica: Descobrir independência dos resíduos 3.3 Pre-coloring (AR) - Força os resíduos a ter a dependência desejada/conhecida que seja compatível com o modelo estatístico.\n Análise de fMRI: Um conjunto de dados fMRI, pode ser visto como um conjunto de elementos cubóides (isto é, voxels) de dimensão variável, cada qual explicados por uma série temporal associada de tantos pontos de tempo quanto os volumes adquiridos por sessão.\nO objetivo de uma análise estatística (convencional) é determinar quais voxels têm um curso de tempo que se correlaciona com algum padrão conhecido de estimulação ou manipulação experimental. O primeiro passo na análise de dados de ressonância magnética funcional é aplicar uma série de transformações de “pré-processamento” com o objetivo de corrigir vários artefatos potenciais introduzidos na aquisição de dados. Cada transformação pode ser aplicada conforme necessário, dependendo do projeto experimental específico ou protocolo de aquisição. As etapas mais típicas incluem o ajuste de diferenças no tempo de aquisição de fatias de imagem individuais, correção do movimento do assunto, distorção dos dados de indivíduos individuais em um espaço comum (“normalização”) e suavização temporal e espacial (ver Jezzard et al., 2002). Após o pré-processamento, a análise de dados é geralmente realizada em duas etapas: uma análise de primeiro nível separada dos dados de cada indivíduo, seguida de uma análise de segundo nível na qual os resultados de vários assuntos são combinados.\nAs etapas de: * coleta de dados * pré-processamento * 1st level * e/ou 2nd level\nOnde as análises são feitas em dois tipos:\n 1st level: Comparação entre ativação em condições no mesmo indivíduo 2nd level: Comparação entre condições em um grupo OU comparação entre grupos de indivíduos  Análise primeiro nível O objetivo da análise estatística de primeiro nível é determinar o quão grande é a contribuição de cada variável preditora \\(x_i\\) para os valores observados de \\(y\\) em um único indivíduo. Isto é, o tamanho de cada parâmetro de escala \\(\\beta_i\\) e se é significativamente diferente de zero.\nSeja no primeiro nível a implementação do GLM:\n\\[ \\begin{align} Y_{t} = \\beta . X_t + \\epsilon_t \\end{align} \\]\nonde, \\(Y\\) é um vector de coluna \\(n × 1\\) representando a série temporal do sinal BOLD associada a um único voxel. X é a matriz design \\(n × p\\), com cada coluna representando uma variável de previsão diferente.\nA abordagem padrão para a análise de fMRI é ajustar o mesmo modelo de forma independente ao tempo de cada voxel. A covariância espacial entre voxels vizinhos é, portanto, tipicamente ignorada no estágio de ajuste do modelo. A presença de mais variáveis de resposta (isto é, voxels) do que observações (ou seja, volumes), juntamente com o objetivo de fazer afirmações topograficamente específicas sobre a atividade BOLD, tem tradicionalmente motivado essa abordagem “massiva-univariada”.\n Análise de grupo - 2nd level: As análises 2nd level se dividem em fixed effects (conclusões nos indivíduos que participaram do estudo) ou mixed effects/random para conclusões de onde os indivíduos foram amostrados. Em mixed effects, utiliza-se um grupo para amostrar um comportamento de uma população.\nNa análise de grupo, podemos aplicar diversos testes de hipóteses, como teste \\(\\lambda^2\\) (chi-quadrado), teste-T, correlação de Pearson. Com o GLM, é possível fazer parte destes testes.\n\\[ \\begin{align} Y_{i} = \\alpha + \\beta_1 . X_i + \\beta_2.Z_i+... + \\epsilon_t \\end{align} \\] supondo: \\(\\epsilon_t\\) com média zero e variância constante (homocedasticidade) e os erros \\(\\epsilon_t\\) são independentes\nExemplo: Suponha que para um voxel X, Y, Z temos os \\(\\beta\\)’s de uma condição experimental para N indivíduos. Como testar se na população de onde os N indivíduos foram amostrados se o \\(\\beta \u0026gt; 0\\)?\nPara N-indivíduos, terei N cérebros para analisar. Para cada indivíduo tenho um \\(\\beta_i\\) atribuído a cada um:\n\\[\\begin{align}= \\begin{bmatrix} \\\\ \\beta_1 \\\\ \\beta_2 \\\\ ... \\\\ \\beta_n \\end{bmatrix} \\end{align}\\] Teste para um grupo: Para testar se esse \\(\\beta\\), basta testar com teste-T se o \\(\\alpha\u0026gt;0\\) considerando o modelo de $ Y = + _t$ (\\(\\epsilon\\) com média zero):\n\\[\\begin{align} Y = \\begin{bmatrix} \\\\ \\beta_1 \\\\ \\beta_2 \\\\ ... \\\\ \\beta_n \\end{bmatrix} \\end{align}\\] e\n\\[\\begin{align} X = \\begin{bmatrix} \\\\ 1 \\\\ 1 \\\\ ... \\\\ 1 \\end{bmatrix} \\end{align}\\] Isso é equivalente a um teste T para uma amostra.\n PRIMEIRO método: Comparando dois grupos: Por exemplo sejam as matrizes:\n\\[\\begin{align} X = \\begin{bmatrix} Controle \\\\ \\beta_1 \\\\ \\beta_2 \\\\ ... \\\\ \\beta_n \\end{bmatrix} \\end{align}\\] e pacientes:\n\\[\\begin{align} X = \\begin{bmatrix} Pacientes \\\\ \\beta_1 \\\\ \\beta_2 \\\\ ... \\\\ \\beta_n \\end{bmatrix} \\end{align}\\] O modelo de GLM utilizado é:\n\\(Y_i = \\beta_1.C_i + \\beta_2.P_i + \\epsilon_t\\) note que não há intercepto \\(\\alpha\\)\ne: \\(Y_i\\) é o coeficiente de ativação do indivíduo:\n\\(i=\\) {1, 2, …, \\(N_c\\), \\(N_c\\), …, \\((N_c+N_p)\\)\n\\(C_i=1\\) se o indivíduo \\(i\\) é controle e zero caso contrário \\(P_i=1\\) se o indivíduo é paciente e zero caso contrário\n\\[ Y= \\left(\\begin{array}{cc} \\beta_1^c \\\\ \\beta_2^c \\\\ ... \\\\ \\beta_N^p \\end{array}\\right), X= \\left(\\begin{array} 1 1 \u0026amp; 0\\\\ 1 \u0026amp; 0 \\\\ 1 \u0026amp; 0 \\\\ ... \u0026amp; ...\\\\ 0 \u0026amp; 1 \\\\ 0 \u0026amp; 1 \\\\ 0 \u0026amp; 1 \\\\ \\end{array}\\right) \\]\nConsiderando a base a qual os 37 primeiros indivíduos são controles saudáveis e os demais são pacientes com Parkinson.\nImplementando no R:\n#Leitura de biblioteca require(AnalyzeFMRI) ## Carregando pacotes exigidos: AnalyzeFMRI ## Carregando pacotes exigidos: R.matlab ## R.matlab v3.6.1 (2016-10-19) successfully loaded. See ?R.matlab for help. ## ## Attaching package: \u0026#39;R.matlab\u0026#39; ## The following objects are masked from \u0026#39;package:base\u0026#39;: ## ## getOption, isOpen ## Carregando pacotes exigidos: fastICA ## Carregando pacotes exigidos: tcltk ## Carregando pacotes exigidos: tkrplot #Leitura dos dados betas = f.read.volume(\u0026quot;grupo37C-P.nii\u0026quot;) dim(betas) ## [1] 45 54 45 92 # imagem axial do décimo individuo: #imagem axial (z=20) do decimo individuo na fatia 20 image(betas[,, 20, 10]) Para um único voxel 20, 20, 20:\nY = betas[20, 20, 20,] X = matrix(0, 92, 2) # Como 1: 37 são controle e do 38:92 são pacientes: # Variável dummy para controles X[1:37, 1] = 1 # Variável dummy para pacientes: X[38:92, 2] = 1 Ajustando o modelo - GLM:\n#Ajustar o GLM #o -1 na formula serve para tirar o intercepto modelo = lm(Y~-1+X[, 1] + X[, 2]) summary(modelo) ## ## Call: ## lm(formula = Y ~ -1 + X[, 1] + X[, 2]) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.50669 -0.15868 -0.03905 0.09441 1.15112 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## X[, 1] 0.48435 0.04685 10.34 \u0026lt;2e-16 *** ## X[, 2] 0.44014 0.03843 11.45 \u0026lt;2e-16 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 0.285 on 90 degrees of freedom ## Multiple R-squared: 0.7256, Adjusted R-squared: 0.7195 ## F-statistic: 119 on 2 and 90 DF, p-value: \u0026lt; 2.2e-16 Se olhar o \\(\\beta_1\\) são as variáveis do grupo controle e \\(\\beta_2\\) do grupo de pacientes.\nAnalisando o teste de hipóteses e a ativação dos respectivos controles. Para ativação \\(beta_1 \u0026gt; 0\\). Olhando o resultado vemos que o p-valor é muito pequeno, portanto, os controles ativam nesse voxel. O mesmo vale para o grupo de pacientes.\nPara entender se o controle ativa MAIS que o de pacientes: \\(\\beta_1 \u0026gt; \\beta_2\\). No R esse teste não é tão simples de se verificar.\n Outro método: Grupos de referência \\(Y_i = \\alpha + \\beta_2.P_i + \\epsilon_t\\) \\(P_i=1\\) se o indivíduo é paciente e zero caso contrário\nPara controles: \\(Y_i = \\alpha + \\epsilon_i\\)\nPara pacientes: \\(Y_i= \\alpha+ \\beta + \\epsilon_i\\) \\(\\beta\\) é o incremento na média em relação aos controles.\nNeste caso:\n\\[ Y= \\left(\\begin{array}{cc} \\beta_1 \\\\ \\beta_2 \\\\ ... \\\\ \\beta_{(N_c+N_p)} \\end{array}\\right), X= \\left(\\begin{array} 1 1 \u0026amp; 0\\\\ 1 \u0026amp; 0 \\\\ 1 \u0026amp; 0 \\\\ ... \u0026amp; ...\\\\ 1 \u0026amp; 1 \\\\ 1 \u0026amp; 1 \\\\ 1 \u0026amp; 1 \\\\ \\end{array}\\right) \\]\nImplementando para o mesmo voxel 20,20,20:\n### METODO GRUPO DE REFERENCIA #Neste caso sera o controle #Observacao: os 37 primeiros indiv #sao controles saudáveis e os demais #sao pacientes com Parkinson #GLM Y = betas[20, 20, 20,] X = matrix(0, 92, 2) #Intercepto X[, 1] = 1 #Variavel dummy para Pacientes X[38:92, 2] = 1 #Ajustar o GLM modelo = lm(Y~X[, 2]) summary(modelo) ## ## Call: ## lm(formula = Y ~ X[, 2]) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.50669 -0.15868 -0.03905 0.09441 1.15112 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 0.48435 0.04685 10.34 \u0026lt;2e-16 *** ## X[, 2] -0.04421 0.06060 -0.73 0.468 ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 0.285 on 90 degrees of freedom ## Multiple R-squared: 0.00588, Adjusted R-squared: -0.005166 ## F-statistic: 0.5323 on 1 and 90 DF, p-value: 0.4675 Analisando especificamente para esse voxel, como \\(\\beta\u0026lt;0\\) é como se o grupo de pacientes possui uma ligeira ativação menor que o grupo de controle, Mas ao verificar o p-valor, pode-se verificar que não é significante.\nPara análise dos mapas, analisamos mais o t-valor.\nFazendo a varredura para todos os voxeis intracranianos (análise de grupo de referência):\n#GLM em todos os voxels intracranianos MAPAT = array(0, c(45, 54, 45, 1)) for(xi in 1:45){ for(yi in 1:54){ for(zi in 1:45){ if(betas[xi, yi, zi, 1] != 0){ Y = betas[xi, yi, zi, ] X = matrix(0, 92, 2) #Intercepto X[, 1] = 1 #Variavel dummy para Pacientes X[38:92, 2] = 1 #Ajustar o GLM modelo = lm(Y~X[, 2]) #Estatistica T do paciente vs controle MAPAT[xi, yi, zi, 1] = summary(modelo)$coef[2, 3] }#fecha if }}}#fecha o for do xi,yi,zi #Salva os mapas em arquivos no formato Analyze (IMG/HDR) f.write.analyze(MAPAT, \u0026quot;MapaControlevsPaciente\u0026quot;, pixdim = c(4, 4, 4), originator = c(23.5, 32.5, 19, 1, 1))    "
},
{
	"uri": "/aulas/12_fnirs/",
	"title": "fNIRS",
	"tags": [],
	"description": "",
	"content": "Espectroscopia do infravermelho próximo. A espectroscopia do infravermelho próximo em funcionamento - fNIRs é uma tecnologia de neuroimagem para mapear o córtex humano, que desde 1977, é empregada para o mapeamento do cérebro de humanos e em animais através de sua oxigenação (Jobsis, 1977). Os tecidos humanos são relativamente transparentes à luz na janela espectral NIR, que é absorvida por compostos pigmentados (cromóforos) ou dispersa em tecidos (Ferrari, 2012). A luz NIR é capaz de penetrar nos tecidos humanos, uma vez que o fator dominante no seu transporte de tecido é a dispersão. A imagem em infravermelho próximo ou a imagem óptica difusa são utilizadas para detectar mudanças simultâneas nas propriedades ópticas do córtex humano a partir de múltiplos locais de medição e exibe os resultados na forma de um mapa ou imagem em uma área específica.\nAtividade cerebral está associada a um número de eventos fisiológicos, alguns associados a mudanças nas propriedades ópticas do tecido cerebral e podem ser avaliadas por técnicas ópticas. As principais vantagens dos métodos ópticos incluem custo relativamente baixo, a especificidade bioquímica, a resolução temporal (na faixa de milissegundos), o potencial para medir simultaneamente os eventos intracelulares e intravasculares e a facilidade com que os dispositivos podem ser transportados (Ferrari, 2012).\nSegundo Delpy (10997), utiliza-se níveis seguros de luz laser (com comprimentos de onda entre 650 e 1000 nm) para inferir a variação do nível de oxigenação do tecido cerebral de forma não invasiva, que penetram no tecido biológico e atingem o córtex, permitindo analisar a oxi-hemoglobina (O2Hb), deoxi-hemoglobina (HHb) e hemoglobina total (tHb; tHb = O2Hb + HHb) do sangue cerebral. Muitos outros cromóforos ainda absorvem a luz mas apenas essas são de importância clínica e exibem absorção dependente da oxigenação. Através delas pode-se buscar um melhor entendimento do acoplamento neuro-vascular, das flutuações neurofisiológicas e da hemodinâmica cerebral.\nA técnica NIRs utiliza:\n Diodo laser e/ou fontes de luz de diodos emissores de luz que abrangem a janela óptica entre 650 e 1000 nm Fibra óptica flexível para transportar a luz NIR da fonte e detector tecidos  Três tipos de NIRS diferentes são usadas, cada uma baseada em um tipo específico de iluminação:\n A modalidade CW ( ou ondas contínuas) que, com base na constante iluminação do tecido, mede a atenuação da luz através da cabeça. Essa modalidade mede apenas as alterações de oxigenação de O2Hb e HHb mas em relação às outras técnicas, oferece as vantagens de baixo custo e facilidade de transporte.\n O método de freqüência-domínio (FD) que, iluminando a cabeça com luz modulada por intensidade, mede a atenuação e o atraso de fase da luz emergente.\n A técnica do domínio do tempo (TD) que, iluminando a cabeça com pulsos de luz curtos, detecta a forma do pulso após a propagação através dos tecidos.\n  As modalidades FD e TD oferecem a possibilidade de caracterizar as propriedades ópticas dos tecidos (absorção e coeficientes de espalhamento reduzidos), dos quais é possível recuperar as concentrações absolutas de O2Hb e HHb.\nAs fibras ópticas são muito adequadas para qualquer posição e postura da cabeça. As medições de NIRS podem ser realizadas em ambientes naturais sem necessidade de restrição ou sedação e a profundidade adequada da penetração da luz NIR (quase a metade da distância do detector fonte) pode ser alcançada usando uma distância do detector em torno de 3cm. A seleção da distância ideal do detector de fonte depende da intensidade da luz NIR e do comprimento de onda, da idade do sujeito e a região da cabeça medida (Ferrari, 2012).\nÀ medida que a luz injetada se difunde em todas as direções dentro dos tecidos da cabeça (couro cabeludo, crânio e espaço subaracnóideo preenchido com líquido cefalorraquidiano) tanto antes como depois de passar pelo tecido cerebral, a sensibilidade de cada par de fontes-detectores exibe uma distribuição espacial da luz NIR através das diferentes camadas com formato similar ao de uma banana (duas extremidades estreitas e uma curva para dentro em direção ao centro).\nA atenuação relativamente alta da luz NIR no tecido é devida à hemoglobina principal do cromóforo (a proteína dos glóbulos vermelhos que faz o transporte de oxigênio) localizada em pequenos vasos (\\(\u0026lt;1 mm\\) de diâmetro) da microcirculação, como leitos capilares, arteriolares e venulares . NIRS é fracamente sensível aos vasos sanguíneos \\(\u0026gt; 1mm\\) porque absorvem completamente a luz.\nConforme apresentado por (Mesquita, 2008), O tecido biológico é altamente espalhador de luz e possui coeficientes de absorção relativamente baixos na região do infravermelho próximo do espectro eletromagnético. Estas propriedades permitem a penetração da luz no tecido e sua conseqüente propagação por alguns milímetros, através dos coeficientes de absorção \\(\\mu_{a}\\)) e de espalhamento (\\(\\mu_s\\)) com valores típicos para estas grandezas no cérebro \\(\\mu_a = 1,4 cm^{-1}\\) e \\(s = 350 cm^{-1}\\). Com, \\(\\mu_a\\) variando significativamente com a concentração e o tipo de hemoglobina presente no tecido. É esta sensibilidade das propriedades ópticas da oxi-hemoglobina (O2Hb) e da deoxihemoglobina (HHb), aliada ao fato de ser baixo o coeficiente de absorção da água nessa região, que permite determinar os níveis de oxigenação do tecido com base no espalhamento de luz.\nDurante ativação cerebral (Mesquita2008), as variações nas concentrações de O2Hb e HHb resultam em variações na absorção da luz dentro do tecido. Para medidas hemodinâmicas funcionais típicas, assume-se que essas variações são pequenas, insuficientes para perturbar o caminho da luz através do tecido podendo ser generalizada através da Lei de Beer-Lambert:\n\\[ \\Delta OD_i(t, \\lambda) = L_{i,j} (\\lambda) \\sum_{j=1}^{N_{vox}}\\Delta\\mu_{a,j}(t, \\lambda) . \\]\nonde, \\(OD\\) é a densidade óptica num detector \\(i\\), \\(j\\) é a fonte, \\(\\lambda\\) é o comprimento da onda, \\(\\mu_a\\) é o coeficiente de absorção do tecido e \\(L_{i,j}\\) é o livre caminho médio no tecido biológico entre a fonte e detector (na ordem de 28 \\(\\mu m\\)).\nNo entanto, essa equação só é válida na ausência de espalhamento. Como o caminho médio da luz depende das propriedades de espalhamento do tecido, usa-se a lei de Beer-Lambert modificada, (MBLL, do inglês ) para contabilizar estes efeitos e levar em conta a propagação difusiva da luz, que inclui um fator de caminho diferencial adicional (\\(l_{DPF}\\)), de forma que \\(OD\\) passa a ser dada por:\n\\[ \\Delta OD_i(t, \\lambda) = \\sum_{n}\\mathcal{E}_n(\\lambda).\\Delta c_n(t).L_{i,j} (\\lambda).l_{DPF}(\\lambda) \\]\nonde a variação de concentração do n-ésimo cromóforo, \\(\\Delta C_n\\), pode ser encontrada através de medidas de intensidade em função do tempo para n diferentes comprimentos de onda. No caso particular de \\(n=2\\), pode-se resolver o sistema e estimar as variações de O2Hb(t) e de HHb(t). Com isso, pode-se ver o coeficiente de extinção, distância entre emissor e detector, propriedades do tecido, etc.\nOs experimentos de NIRS, no entanto, medem apenas as variações relativas de oxigenação do tecido. Os valores absolutos não são disponíveis, principalmente levando-se em consideração as diferentes estruturas cerebrais pelas quais a luz atravessa. Outras limitações também são: (a) a interferência da espessura do crânio (medidas cerebrais) ou da espessura do tecido adiposo (medidas musculares); (b) a contribuição controversa desconhecida da mioglobina no sinal muscular NIRS; (c) o efeito do volume sanguíneo muda no comprimento do tecido e, consequentemente no volume de amostra observado; (d) a dificuldade de prever o quanto de uma mudança de sinal NIRS observada é devido ao fluxo sanguíneo cerebral vs. couro cabeludo, ou (e) mudanças simultâneas no fluxo e no volume. Ainda assim, dado o fato de que a fração do volume de sangue arterial é de aproximadamente 30% no cérebro humano, a técnica NIRS oferece a possibilidade de obter informações sobre alterações de oxigenação que ocorrem dentro do compartimento venoso, sendo uma técnica bastante eficaz para detectar zonas de ativação cerebral.\nAo longo do tempo, o que se altera nos dados de fNIRS é a variação de oxyhemoglobina e deoxyhemoglobina.\nNo caso da coleta, o canal é o caminho entre o emissor e o detector. A montagem é escolhida de forma a varrer as regiões cerebrais as quais se pretende estudar (aprox 3cm).\nhttp://www.youtube.com/watch?v=CJIZkZ2ol5A\nE também:\nhttp://www.youtube.com/watch?v=3LMXiDzcANQ\nRealizando a leitura dos dados de fNIRS no R: # Os dados já foram preprocessados # - PCA para correcao de movimento # - retirar outliers # - filtro temporal: passa-banda (0.001-0.1Hz) #Leitura de dados OXY = read.table(\u0026quot;Oxy781HZ30sBlock.txt\u0026quot;, header=F) DEOXY = read.table(\u0026quot;Deoxy781HZ30sBlock.txt\u0026quot;, header=F) Analisando o tamanho do arquivo e a taxa de amostragem:\n# Taxa de amostragem do equipamento HZ = 7.81 dim(OXY) ## [1] 2660 20 dim(DEOXY) ## [1] 2660 20 # Logo, temos de tempo de coleta: tempo = dim(OXY)/HZ tempo ## [1] 340.588988 2.560819 ts.plot(OXY[, 1]) ts.plot(DEOXY[, 1]) #Tarefa block-design - 30s COND = 330 Considerando uma tarefa que intercala Repouso e tarefa de 30s, ou seja nas seguintes condições (convertendo para frames): R: 1:234 T: 235:469 R: 470:703 T: 704:937 R: 938:1172 T: 1173:1406 R: 1407:1640 T: 1641:1874 R: 1875:2109 T: 2110:2343 R: 2344:2577\n#Tarefa block-design - 30s COND = array(0, 2577) #2577 para os primeiros 330s COND[235:469] = 1 COND[704:937] = 1 COND[1173:1406] = 1 COND[1641:1874] = 1 COND[2110:2343] = 1 ts.plot(COND) Considerando a função glover para convolução pela HRF canônica, para verificar como a Oxyhemoglobina se comporta.\nPara prever o desenho experimental pela HRF, similar às aulas de ressonância:\nglover = function(HZ){ a1 = 6 a2 = 12 b1 = 0.9 b2 = 0.9 d1 = 5.4 d2 = 10.8 c = 0.35 x = seq(0, 30, 1/HZ) # HZ is the Sampling Rate (Heartz) glover1 = ((x/d1)^a1)*exp((-x+d1)/b1) glover2 = ((x/d2)^a2)*exp((-x+d2)/b2) G = glover1-c*glover2 return(G) } #HRF canonica HRF = glover(HZ) #Convolucao da condicao da tarefa pela HRF X = filter(COND, HRF, method=\u0026quot;convolution\u0026quot;, side=1) ts.plot(X) Para o comportamento da deoxy, espero o comportamento inverso (deoxy está negativamente correlacionada com a oxy).\nEstamos modelando de forma similar: \\[ Y_t = \\alpha + \\beta.X_t + \\epsilon_T\\]\n# Vetor que contem as estatisticas t dos betas # do GLM para cada canal (nesse experimento são 20) mapaToxy = array(0, 20) mapaTdeoxy = array(0, 20) for(canal in 1:20){ # ajuste do GLM para oxy # o que antes eram todos os voxeis de fMRI, em NIRS são os 20 canais # o modelo prevê a OXY de cada canal em funço da HRF convoluída da cond. # dessa forma, ao ter cond =1 pra tarefa e 0 para repouso, o teste: modelo = lm(OXY[1:2577, canal]~X) mapaToxy[canal] = summary(modelo)$coef[2, 3] #estat. t #ajuste do GLM para deoxy modelo = lm(DEOXY[1:2577, canal]~X) mapaTdeoxy[canal] = summary(modelo)$coef[2, 3] #estat. t } O mapa é o resultado do teste estatístico em todos os canais.\n modelo1 = lm(OXY[1:2577, 1]~X) mapaToxy[canal] = summary(modelo1)$coef[2, 3] #estat. t summary(modelo1)  ## ## Call: ## lm(formula = OXY[1:2577, 1] ~ X) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.0008340 -0.0001565 -0.0000107 0.0001493 0.0009014 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) -3.349e-05 6.535e-06 -5.124 3.24e-07 *** ## X 3.263e-06 3.686e-07 8.851 \u0026lt; 2e-16 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 0.0002464 on 2341 degrees of freedom ## (234 observations deleted due to missingness) ## Multiple R-squared: 0.03238, Adjusted R-squared: 0.03197 ## F-statistic: 78.34 on 1 and 2341 DF, p-value: \u0026lt; 2.2e-16  #ajuste do GLM para deoxy modelo2 = lm(DEOXY[1:2577, 1]~X) mapaTdeoxy[canal] = summary(modelo2)$coef[2, 3] summary(modelo2) #estat. t ## ## Call: ## lm(formula = DEOXY[1:2577, 1] ~ X) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.997e-04 -1.231e-04 6.810e-06 1.172e-04 4.925e-04 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 6.990e-06 4.636e-06 1.508 0.1317 ## X 4.553e-07 2.615e-07 1.741 0.0818 . ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 0.0001748 on 2341 degrees of freedom ## (234 observations deleted due to missingness) ## Multiple R-squared: 0.001293, Adjusted R-squared: 0.0008668 ## F-statistic: 3.032 on 1 and 2341 DF, p-value: 0.08178 Uma consideração do GLM é que os erros (resíduos) são independentes. Na prática, como a taxa de amostragem do NIRS é superior a do fMRI, o problema da autocorrelação dos resíduos é maior. Para mapas de ativação estatísticos, os procedimentos de pre-whitening, pre-colouring ou semi-paramétricos são necessários pois os valores de teste T do NIRS acabam com uma magnitude muito maior.\n Coleta de fNIRS Na aula o professor mostrou o equipamento NIRSport da empresa NIRx (Alemanha). Além da empresa NIRx, tem a Artinis e a Hitashi.\nNo software NIRx Star que se utiliza para fazer a calibração dos optodos e coleta do sinal.\nNa calibração pode-se corrigir o ajuste da touca com:\n Verde: Sinal excelente Amarelo: Sinal bom Vermelho: Sinal ruim Branco: Canal morto  Ao iniciar a gravação, pode-se ver os sinais: vermelho a oxihemoblogina (HbO) e azul a desoxihemoglobina (Hb). Na onda, é possível ver o artefato cardíaco no sinal (mais forte na oxy pois vem das arteríolas). A deoxy se encontra nas vênulas, que é mais fraco. Uma vantagem em relação ao EEG é que como se trata de luz infravermelho e não pulsos elétricos, não há problemas de artefatos ocasionados por movimentos ou fala.\nPode-se utilizar para atividades de neurofeedback.\nNa aula, foi mostrado com um voluntário um experimento de geração de números aleatórios, intercalando dois tipos de atividades:\n Contagem de 0-9 Gerração de números aleatórios  Após a coleta, o professor mostrou como processa no NIRSLab.\n Carregar arquivo coletado Correção de triggers (marcação do experimento) Limpeza do sinal: Remoção de spikes e filtragem do sinal: escolha dos filtros. Na filtragem são filtrados comprimentos de onda e não a oxy e deoxy. A correção do movimento não é realizada no software Cômputo de estados hemodinâmicos: Estabelecer parâmetros do coeficiente de absorção de Beer-Lambert e cômputo de estados hemodinâmicos. Aplicação do GLM: Em SPM Level, pode-se escolher qual onda trabalhar. Em “Specific basis” escolhemos a HRF canônica, com a leitura dos triggers. O pre-colouring e pre-whitening também é possível adicionar nas configurações.  Nesse caso, o GLM para cada canal é:\n\\[ Y_t = \\alpha + \\beta.X_t + \\epsilon_t \\]\ne na visualização é possível ver cada \\(\\beta\\) (azul é para deativação e vermelho para ativação). As regiões laterais são o córtex prefrontal dorsolateral (para funções executivas) e o medial (região da default mode).\nPara ver essas regiões são estatísticamente significantes, é necessário especificar o contraste (marcar com 1 e 0). É possível verificar por exemplo maior ativação no hemisfério oposto a mão que escreve.\nNo experimento sugere-se que as tarefas sejam alternadas por conta do artefato de inclinação. No desenho experimental, alterna-se as tarefas para garantir que a variação da hemodinâmica seja realmente da tarefa cognitiva.\nProva: Sobre NIRs.\n  "
},
{
	"uri": "/aulas/13_conectividade/",
	"title": "Conectividade - seed to voxel",
	"tags": [],
	"description": "",
	"content": "Vimos anteriormente os testes de ativação de cada voxel. Analisar o cérebro todo desta forma demanda muito cálculo computacional, por isso os estudos de conectividade entre um conjunto de regiões de interesse (ROI) têm ganhado mais espaço nas pesquisas.\nEssa análise é realizada para conhecer quais regiões do cérebro estão sincronizadas nas mais diversas situações, desde estados de repouso quanto realizando tarefas cognitivas. É a partir dessa análise que geramos o chamado conectoma (do inglês connectome), isto é, uma rede de conexões entre as diferentes regiões cerebrais.\nConectividade estrutural Baseada na análise do movimento das moléculas de água no tecido cerebral in vivo, a tractografia é uma moderna técnica de ressonância magnética que mostra a posição, a anatomia e a integridade dos tratos da substância branca no encéfalo e na medula, conforme a direção de suas fibras.\nA Conectividade efetiva busca estudar as relações causais entre as atividades. Também é obtida por imagens funcionais. Utiliza-se Dynamic Causal Models (DCM), Causalidade de Granger entre outros métodos.\n Conectividade funcional Para análise de conectividade funcional, alguns métodos são aplicados para análise, conforme os objetivos do estudo:\n Seed-to-voxel (mapas de conectividade): Dada uma região de interesse (seed), obter um mapa de correlações com essa seed. O output é um mapa de correlação com esse ponto.\n ROI-to-ROI (grafos de conectoma) - ROI: Region of interest. O output é um grafo.\n  Uma das aplicações da matriz de correlação é através de grafos, com os ROIs constituindo os nós e as conexões entre cada nós as arestas, formando uma rede de conexões.\nVárias propriedades destas redes são utilizadas para análise das associações entre as ROIS, por exemplo temos o grau da rede, que corresponde ao número médio de conexões da mesma, ou medidas mais locais como os hubs que representam a ROI com maior número de conexões. Assim, a partir da construção da matriz de correlação das ROIs, podemos realizar um grande número de medidas capazes de fornecer informações as redes de conectividade do cérebro humano.\nConstruindo computacionalmente a análise de conectividade entre ROIs.\nPara um determinado voxel escolhido de semente (seed) definiremos a região de interesse a partir dele: Escolhemos o Cingulo Posterior centralizado em x=23, y=19 ,z=27 (processamos um cubo de três voxeis centralizado neste):\n#Carregar a biblioteca require(AnalyzeFMRI) ## Carregando pacotes exigidos: AnalyzeFMRI ## Carregando pacotes exigidos: R.matlab ## R.matlab v3.6.1 (2016-10-19) successfully loaded. See ?R.matlab for help. ## ## Attaching package: \u0026#39;R.matlab\u0026#39; ## The following objects are masked from \u0026#39;package:base\u0026#39;: ## ## getOption, isOpen ## Carregando pacotes exigidos: fastICA ## Carregando pacotes exigidos: tcltk ## Carregando pacotes exigidos: tkrplot #Leitura do arquivo volume = f.read.volume(\u0026quot;RESTING.img\u0026quot;) dim(volume) ## [1] 45 54 45 450 #Dimensoes XMAX = dim(volume)[1] YMAX = dim(volume)[2] ZMAX = dim(volume)[3] TMAX = dim(volume)[4] #Selecionar regiao-de-interesse (ROI) #Cingulo Posterior centralizado em x=23, y=19 ,z=27 #ROI será um cubo centralizado neste voxel SEED = array(0, TMAX) for(ti in 1:TMAX){ SEED[ti] = mean(volume[22:24, 18:20, 26:28, ti]) } ts.plot(SEED) Para corrigir os artefatos sistêmicos (que podem gerar correlação espúrias), apliquemos o GSR - Global Signal Regression nos sinais BOLDs das ROIs para então recalcular a matriz de conectividade.\nO Global Signal Regression é um método de correção para remoção de artefatos que consiste em ajustar um modelo de regressão linear, considerando o sinal BOLD de cada ROI como a variável resposta e o Global Signal (GS) como variável preditora: ou seja, verifica o que é comum a todos e retira o sinal global antes de calcular as correlações\nÉ frequente realizar também (incluir como preditoras) os 6 parâmetros de movimentação da cabeça obtidos no pre-processamento. Além disso, também é comum em estudos com crianças e populações clínicas utilizar o método de scrubbing, que se baseia em descartar os scans colhidos durante grandes movimentações da cabeça.\nPara calcular o GS (Global Signal), devemos normalizar o sinal BOLD das ROIS para media 0 e variância 1 (z-score), a fim de retirar a variabilidade de cada série temporal que poderia causar alguma correlação espúria.\nConsideramos que essas componentes em comum estão contidas na média, por isso fazemos com que a média do sinal seja zero. Após o processo do GSR, teremos retirado, ou pelo menos minimizado, os efeitos dos artefatos sistêmicos nos sinais que poderiam causa correlações espúrias:\n# Global signal - tirando a média de tudo e colocando no sinal global, deveria ser apenas nos vóxeis intracranianos #Global signal GSR = array(0,TMAX) for(ti in 1:TMAX){ #na realidade deveria ser apenas dos voxels intracranianos GSR[ti] = mean(volume[,,,ti]) } ts.plot(GSR) Uma vez aplicado o GSR para remoção de artefatos sistêmicos, utiliza-se o conceito de matriz de conectividade para verificar as similaridades entre as redes cerebrais de diferente indivíduos.\nPodemos verificar essa semelhança entre as redes de diversas maneiras, podemos comparar as médias, máximos e/ou mínimo das correlações; ou podemos comparar as métricas de rede, como grau, coeficiente de centralidade, hubs, coeficiente de clusterização.\nPara este exercício, Com 450hz numa taxa de 0.5hz, temos 900s. Armazenando o Mapa de Conectividade Funcional, com utilização do Coeficiente de correlação de Pearson:\nO mapa constitui no processamento de para cada voxel a comparação com a região de interesse (SEED), armazenando os resultados de sua correlação.\nMAPA = array(0, c(XMAX, YMAX, ZMAX, 1)) for(xi in 1:XMAX){ for(yi in 1:YMAX){ for(zi in 1:ZMAX){ if(volume[xi, yi, zi, 1] != 0){ #mascara intracraniana #Coef. de Correlacao de Pearson MAPA[xi, yi, zi, 1] = cor(SEED, volume[xi, yi, zi,]) }#fecha o if }}}#fecha os for #Salva os mapas em arquivos no formato Analyze (IMG/HDR) f.write.analyze(MAPA,\u0026quot;MapaConectividade\u0026quot;, pixdim = c(4, 4, 4), originator = c(23.5, 32.5, 19, 1, 1)) Olhando no MRCRO é possível ver o seed altamente ativado (porque a correlação é 1 e seu entorno possui suavização espacial, que justifica a alta ativação com a região).\n#Transformacao de Fisher z = log((1+MAPA)/(1-MAPA)) f.write.analyze(MAPA,\u0026quot;MapaConectividadeZ\u0026quot;, pixdim = c(4, 4, 4), originator = c(23.5, 32.5, 19, 1, 1))  "
},
{
	"uri": "/aulas/16_analise_de_coerencia/",
	"title": "Análise de Coerência",
	"tags": [],
	"description": "",
	"content": "Autocovariância: \\(X_t\\)\n\\[ \\lambda(h) = cov(X_t, X_t-h) \\]\nCovariância cruzada:\n\\[ \\lambda(h)_{XY} = cov(X_t, X_t-h) \\] Estimador -\nEstimador -\n\\[ \\hat{\\lambda}(h)_{XY} = \\]\nO espectro (ou densidade espectral) também pode ser obtido por meio da Transformada de Fourier da função de autocovariância.\nO espectro cruzado é a TDF da função da covariância cruzada.\nCalcularemos a coerência espectral usando os dados de eletrofisiologia:\n##################### Analise Espectral - Olhos Fechados #leitura dos sinais sinais=read.table(\u0026quot;OlhosFechados.txt\u0026quot;,header=FALSE) #leitura do nome dos canais nomescanais=scan(\u0026quot;NOMEScanais.txt\u0026quot;,what=\u0026quot;string\u0026quot;) dim(sinais) ## [1] 45315 32 nomescanais  ## [1] \u0026quot;Fp1\u0026quot; \u0026quot;Fp2\u0026quot; \u0026quot;F7\u0026quot; \u0026quot;F3\u0026quot; \u0026quot;Fz\u0026quot; \u0026quot;F4\u0026quot; \u0026quot;F8\u0026quot; \u0026quot;FC5\u0026quot; \u0026quot;FC1\u0026quot; \u0026quot;FC2\u0026quot; ## [11] \u0026quot;FC6\u0026quot; \u0026quot;T7\u0026quot; \u0026quot;C3\u0026quot; \u0026quot;Cz\u0026quot; \u0026quot;C4\u0026quot; \u0026quot;T8\u0026quot; \u0026quot;TP9\u0026quot; \u0026quot;CP5\u0026quot; \u0026quot;CP1\u0026quot; \u0026quot;CP2\u0026quot; ## [21] \u0026quot;CP6\u0026quot; \u0026quot;TP10\u0026quot; \u0026quot;P7\u0026quot; \u0026quot;P3\u0026quot; \u0026quot;Pz\u0026quot; \u0026quot;P4\u0026quot; \u0026quot;P8\u0026quot; \u0026quot;PO9\u0026quot; \u0026quot;O1\u0026quot; \u0026quot;Oz\u0026quot; ## [31] \u0026quot;O2\u0026quot; \u0026quot;PO10\u0026quot; #Taxa de amostragem HZ=250 #Tamanho da epoca (janela) em segundos TAMsegundos=5 #Tamanho da epoca (janela) em caselas do vetor de sinais TAM=TAMsegundos*HZ #Numero de epocas Nepocas=floor(nrow(sinais)/TAM) #Numero de canais Ncanais=ncol(sinais) # Por motivos didático, primeiramente vamos calcular # a coerencia entre dois canais sem dividir em epocas Por questões didáticas, calculemos a coerência entre dois canais sem dividir em épocas: * F7 canal 3 * P7 canal 23 * O1 canal 29\nCalculando a coerência entre O1 e F7 e vendo seu gráfico:\ncoerencia = spectrum(sinais[, c(29,3)], spans = c(100, 100)) #Grafico da coerencia plot((HZ/2)*(1:nrow(coerencia$coh))/nrow(coerencia$coh),coerencia$coh, type=\u0026quot;l\u0026quot;,xlab=\u0026quot;Frequencia (Hz)\u0026quot;,ylab=\u0026quot;Coerencia\u0026quot;) #Coerencia entre F7 e P7 coerencia=spectrum(sinais[,c(3,23)],spans=c(100,100)) #Grafico da coerencia plot((HZ/2)*(1:nrow(coerencia$coh))/nrow(coerencia$coh),coerencia$coh, type=\u0026quot;l\u0026quot;,xlab=\u0026quot;Frequencia (Hz)\u0026quot;,ylab=\u0026quot;Coerencia\u0026quot;) #### Calculo da coerencia media entre epocas #1-Coerencia entre O1 e F7 #2-Coerencia entre O1 e P7 #3-Coerencia entre F7 e P7 y1=0 y2=0 y3=0 #Calcula a media entre épocas for(epoca in 1:Nepocas){ #Descobrir caselas de inicio e fim de cada epoca INICIO=TAM*(epoca-1)+1 FIM=epoca*TAM y1=y1+spectrum(sinais[INICIO:FIM,c(29,3)],spans=c(15,15))$coh y2=y2+spectrum(sinais[INICIO:FIM,c(29,23)],spans=c(15,15))$coh y3=y3+spectrum(sinais[INICIO:FIM,c(23,3)],spans=c(15,15))$coh }#for da epoca  y1=y1/Nepocas y2=y2/Nepocas y3=y3/Nepocas #Grafico da coerencia media plot((HZ/2)*(1:nrow(y1))/nrow(y1),y1, type=\u0026quot;l\u0026quot;,xlab=\u0026quot;Frequencia (Hz)\u0026quot;,ylab=\u0026quot;Coerencia media\u0026quot;) lines((HZ/2)*(1:nrow(y2))/nrow(y2),y2,col=2) lines((HZ/2)*(1:nrow(y3))/nrow(y3),y3,col=4) legend(\u0026quot;topright\u0026quot;,c(\u0026quot;O1-F7\u0026quot;,\u0026quot;O1-P7\u0026quot;,\u0026quot;F7-P7\u0026quot;),lty=c(1,1,1),col=c(1,2,4)) #Grafico da coerencia media plot((HZ/2)*(1:nrow(y1))/nrow(y1),y1, type=\u0026quot;l\u0026quot;,xlab=\u0026quot;Frequencia (Hz)\u0026quot;,ylab=\u0026quot;Coerencia media\u0026quot;,ylim=c(0,1)) lines((HZ/2)*(1:nrow(y2))/nrow(y2),y2,col=2) lines((HZ/2)*(1:nrow(y3))/nrow(y3),y3,col=4) legend(\u0026quot;topright\u0026quot;,c(\u0026quot;O1-F7\u0026quot;,\u0026quot;O1-P7\u0026quot;,\u0026quot;F7-P7\u0026quot;),lty=c(1,1,1),col=c(1,2,4)) "
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/aulas/14_roitoroi/",
	"title": "Conectividade - ROI to ROI",
	"tags": [],
	"description": "",
	"content": "Nesta aula, aplicaremos os conceitos de conectividade funcional entre regiões de interesse (ROI to ROI).\nPara isso, tomaremos um conjunto de regiões (ROIS), que no caso podem ser mapas já existentes ou criadas de acordo com a necessidade do estudo. A partir das correlações dos sinais BOLD médio dessas regiões podemos inferir se as mesmas estão ao não correlacionadas. Para a realização deste tipo de análise devemos seguir os seguintes passos (NOTAS DE AULA DA CÂNDIDA BARRETO):\nColeta dos dados de fMRI Pré-processamento do sinal Escolha das ROIS - Veremos a seguir Descartar alguns pontos iniciais dos sinais BOLD das ROIS, que por problemas de estabilização do sinal causam um artefato no início da medida que pode levar a correlações espúrias Extrair o sinal BOLD médio de cada ROI Criar uma matriz de correlação com dimensão igual a dimensão da matriz armazenando os resultados do sinal BOLD médio: Matriz quadrada em que cada elemento aponta a intensidade da correlação entre o sinal BOLD médio de cada região. Dessa forma, a diagonal principal é 1 (correlação dele com ele mesmo) Escolher uma métrica para quantificar a intensidade da associação entre cada região. Essa métrica pode ser a média, o máximo, o valor absoluto da correlação, ou qualquer outra que seja relevante para o estudo em questão.  #Carregar a biblioteca require(AnalyzeFMRI) ## Carregando pacotes exigidos: AnalyzeFMRI ## Carregando pacotes exigidos: R.matlab ## R.matlab v3.6.1 (2016-10-19) successfully loaded. See ?R.matlab for help. ## ## Attaching package: \u0026#39;R.matlab\u0026#39; ## The following objects are masked from \u0026#39;package:base\u0026#39;: ## ## getOption, isOpen ## Carregando pacotes exigidos: fastICA ## Carregando pacotes exigidos: tcltk ## Carregando pacotes exigidos: tkrplot #Leitura do arquivo de Resting-state fMRI pre-processada fmri = f.read.volume(\u0026quot;RESTING.img\u0026quot;) #Leitura do Atlas com as ROIs atlas = f.read.volume(\u0026quot;xbrodmann.img\u0026quot;) #Checar dimensoes das imagens dim(fmri) ## [1] 45 54 45 450 dim(atlas) ## [1] 181 217 181 1 Veja que as dimensões são diferentes (o atlas possui voxels isotrópicos em 1mm e o dado de fmri em 4mm): o atlas possui quatro vezes mais dados que o fmri. Então precisaremos antes de tudo, fazer uma subamostragem da imagem grande para a menor, com razão 4 para 1 dos voxels do atlas.\nPrimeiro, identificando as dimensões:\nXMAX = dim(fmri)[1] YMAX = dim(fmri)[2] ZMAX = dim(fmri)[3] TMAX = dim(fmri)[4] Fazendo uma repetição do dado e o devido ajuste para centralizar na posição \\((4x-2)\\):\natlas4mm = array(0, c(XMAX, YMAX, ZMAX, 1)) for(xi in 1:XMAX){ for(yi in 1:YMAX){ for(zi in 1:ZMAX){ atlas4mm[xi, yi, zi, 1] = atlas[4*xi-2, 4*yi-2, 4*zi-2, 1] }}}#fecha o for Agora, pode-se ver que o atlas e o fmri possuem as mesmas dimensões.\nSalvando o atlas subamostrado:\n#Salva o atlas subamostrado espacialmente f.write.analyze(atlas4mm,\u0026quot;atlas4mm\u0026quot;, pixdim=c(4,4,4), originator=c(23.5,32.5,19,1,1)) Pretendemos ver o sinal BOLD representativo na região/área:\nIdentificando o número de regiões (saber quantas ROIS teremos e então construirmos a nossa matriz de #conectividade)\n#Extrair o sinal BOLD representativo de cada regiao de interesse ROI NOMESroi = names(table(atlas4mm)) #de 2 em diante para eliminar AR NOMESroi = NOMESroi[2:length(NOMESroi)] #Numeros de ROIs Nroi = length(NOMESroi) Objetivo é ver a conectividade de cada ROI em cada nó no cérebro. Primeiro definimos uma matriz nula para armazenar o sinal de saída com número de linhas igual ao número de pontos no tempo, e número de colunas igual ao número de ROIS que quero analisar.\nNa sequência, calculamos o sinal BOLD medio de cada ROI para cada ponto no tempo (IX contém os voxeis da ROI).\nBOLD = matrix(0, TMAX, Nroi) for(roi in 1:Nroi){ #localiza os voxels com o label/nome respectivo da roi de interesse IX = which(atlas4mm == NOMESroi[roi]) #Extrai o sinal BOLD medio da ROI for(ti in 1:TMAX){ BOLD[ti, roi] = mean(fmri[,,,ti][IX]) } } ts.plot(BOLD) Para lidar com movimento, poderíamos fazer diversos tratamentos que não fizemos aqui faremos apenas a eliminação do sinal médio comum a todos que atrapalha, tirando o sinal médio de tudo (sinal global) e ficar com os resíduos usando GLM:\n# Global-signal-regression - GSR BOLD2 = BOLD GS = rowMeans(BOLD) for(roi in 1:Nroi){ BOLD2[, roi] = lm(BOLD[, roi]~GS)$res } Regress-out o GS (reduz a influência de componentes sistemáticas, i e, fisiológicas). Faz a regressão linear considerando o sinal BOLD de cada região como variável resposta e o GS como preditora e guarda os resíduos.\nO resultado de BOLD é uma matriz contendo as medias dos sinais de cada ROI ao #longo do tempo. Identificando a matriz de correlação de todos com todos. Usamos a função COR, criando uma matriz de conectividade:\n# Análise de conectividade funcional ROI-to-ROI COR = cor(BOLD2) #matriz de correlacao Olhando um trecho, é possível ver as correlações, onde corr de um com ele mesmo resulta em 1:\nCOR[1:5, 1:5] ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1.0000000 0.58954468 0.4458445 0.25629036 0.22104731 ## [2,] 0.5895447 1.00000000 0.6492590 0.32984228 0.01978718 ## [3,] 0.4458445 0.64925899 1.0000000 0.80351790 -0.14624426 ## [4,] 0.2562904 0.32984228 0.8035179 1.00000000 0.04417543 ## [5,] 0.2210473 0.01978718 -0.1462443 0.04417543 1.00000000 Precisamos analisar a matriz de conectividade funcional. Para a Matriz de adjacência do grafo, primeiramente, devemos lidar com o sinal negativo (+/-) dos elementos desta matriz de correlações.\nA abordagem mais comum, é simplesmente tomar os valores em módulo (ignorar o sinal e pegar o valor absoluto). Ou ainda, também é frequente zerar esses valores negativos, deixando somente os positivos (existem outras formas de lidar com o sinal que também poderiam ser exploradas).\nGRAFO NÃO DIRECIONADO (IDA E VOLTA IGUAL) E GRAFO PONDERADO (COM PESOS NAS ARESTAS/ WEIGHTED GRAPH).\nCom a matriz de adjacência identificamos quem é mais hub e menos hub (importância no grafo):\n#Grafos ponderados - Matriz de adjacencia do grafo #Undirected weighted graph GP = abs(COR) #zera a diagonal principal: diag(GP) = 0 Visualizando:\nGP[1:5, 1:5] ## [,1] [,2] [,3] [,4] [,5] ## [1,] 0.0000000 0.58954468 0.4458445 0.25629036 0.22104731 ## [2,] 0.5895447 0.00000000 0.6492590 0.32984228 0.01978718 ## [3,] 0.4458445 0.64925899 0.0000000 0.80351790 0.14624426 ## [4,] 0.2562904 0.32984228 0.8035179 0.00000000 0.04417543 ## [5,] 0.2210473 0.01978718 0.1462443 0.04417543 0.00000000 Como métrica para comparar as redes, foi usado o grau da rede, que é o número médio de conexões existentes.\nO número máximo de conexões é determinado então a partir da soma dos elementos da linha da matriz de conexões e subtraindo o 1 das correlações da diagonal principal (dados de ROI com ele mesmo).\nPara ver medidas de centralidade (soma de todas as conexões):\nMétrica para comparar as redes - Foi usado aqui o grau da rede, que é o número médio de conexões.\n# Calculo do degree/grau de cada ROI degree = colSums(GP) # (poderia ser a media tb) degree ## [1] 8.877748 7.328348 8.905946 8.174263 10.272278 6.491391 11.461344 ## [8] 10.433433 10.409477 7.244085 10.680901 8.485345 8.609147 9.199811 ## [15] 9.118235 8.857685 8.421214 5.706259 7.529261 7.477560 5.685950 ## [22] 7.601596 7.204188 6.060172 9.643387 7.787061 5.282564 9.593935 ## [29] 8.103715 8.474427 10.079470 6.307135 6.660861 7.623800 9.875775 ## [36] 9.189755 8.593940 9.202202 8.412814 7.318565 6.579100 Para criar um mapa de correlação vamos ranquear os degrees para termos uma ordem de organização. Podemos visualizar o mais importante, e normaliza-lo 0-1:\ndegreeNorm = rank(degree)/Nroi hist(GP) Numa análise arbitrária, com muitas conexões, temos muitos ruídos. Tornando de forma binária a partir de um limiar facilita a leitura.\nGrafo não ponderado - Matriz de adjacência: Nas medidas de centralidade, temos soma das conexões. Como temos muitas regiões, essas somas ficam grandes, aumentando ruído. Por isso, transformamos o grafo em binário.\n#Grafo nao-ponderado - Binários - Matriz de adjacencia #Undirected unweighted graph LIMIAR = 0.2 GNP = GP GNP[which(GP \u0026lt;= LIMIAR)] = 0 GNP[which(GP \u0026gt; LIMIAR)] = 1 Determinando um limiar para essa ponderação:\n#Grafos Nao-ponderados (binarios) LIMIAR = 0.2 GNP = GP GNP[which(GP \u0026lt;= LIMIAR)] = 0 GNP[which(GP \u0026gt; LIMIAR)] = 1 #Calculo do Degree em cada ROI degreeNP = colSums(GNP) #Normaliza para 0 e 1 degreeNormNP = rank(degree)/Nroi plot(degree, degreeNP) cor(degree, degreeNP) ## [1] 0.8921288 Definindo um mapa de centralidade de grau:\n#Construir um mapa de centralidade MAPA = array(0, c(XMAX, YMAX, ZMAX, 1)) for(roi in 1:Nroi){ #Identificar os voxels com o label respectivo da ROI IX = which(atlas4mm == NOMESroi[roi]) MAPA[,,,1][IX] = degreeNorm[roi] } Salvando o mapa de correlação para gerar uma imagem de visualização para verificar a intensidade da correlação:\n#Salva os mapas em arquivos no formato Analyze (IMG/HDR) f.write.analyze(MAPA,\u0026quot;MAPAROItoROI\u0026quot;, pixdim = c(4, 4, 4), originator = c(23.5, 32.5, 19, 1, 1)) Com esse mapa, no MRICro podemos visualizar quem tem mais ou menos relevância, ou seja as regiões com correlações mais intensas.\n"
},
{
	"uri": "/aulas/15_fingerprint/",
	"title": "Fingerprint",
	"tags": [],
	"description": "",
	"content": "Fingerprint é a impressão digital das pessoas. Análise de Fingerprint e Connectoma se trata de explorar o porquê sermos únicos.\nOs estudos de ressonância magnética funcional (fMRI) normalmente colapsam dados de muitos sujeitos, mas a organização funcional do cérebro varia entre cada um. Aqui estabelecemos que essa variabilidade individual é robusta e confiável, usando dados do CORR para identificar perfis de conectividade funcional e como atuam como uma “impressão digital” que pode identificar com precisão os indivíduos de um grande grupo.\nA prova será de Seed to Voxel, análise ROI to ROI e Fingerprint.\nOs dados desse experimento contém dados chineses de Beijing, chamado Consortium for Reliability and Reproducibility (CoRR) (http://fcon_1000.projects.nitrc.org/indi/CoRR/html/)\nPara cada uma das 333 ROIs, é possível ver as subredes cerebrais.\nRealizando análise de todas as regiões corticais:\n#Leitura do ID dos sujeitos nomes = scan(\u0026quot;CARAS.txt\u0026quot;, what = \u0026quot;string\u0026quot;) Nsujeitos = length(nomes) # numero de individuos A matriz tem um pouco mais que as 333 regiões. Há regiões da default mode, região cinzenta que não estão no atlas e por isso preciso retirar.\nRealizando a leitura da matriz de conectividade funcional de cada indivíduo. São 61 indivíduos em duas leituras distintas com três meses de diferença:\n#Leitura dos arquivos com as matrizes de correlacao SCAN1 = array(0, c(Nsujeitos, 333, 333)) SCAN2 = array(0, c(Nsujeitos, 333, 333)) Realizando a leitura dos sujeitos:\nfor(sujeito in 1:Nsujeitos){ # Leitura de dados do SCAN1 # Concatena o prefixo e sufixo no ID do sujeito STRINGNOME = paste(\u0026quot;S1-GordonConnCOR-\u0026quot;, nomes[sujeito], \u0026quot;.txt\u0026quot;, sep=\u0026quot;\u0026quot;) a = read.table(STRINGNOME) # Extrai somente as linhas e colunas de interesse SCAN1[sujeito,,] = as.matrix(a[5:337, 5:337]) #pega somente as ROIS do atlas # Leitura de dados do SCAN2 STRINGNOME = paste(\u0026quot;S2-GordonConnCOR-\u0026quot;, nomes[sujeito], \u0026quot;.txt\u0026quot;, sep=\u0026quot;\u0026quot;) a = read.table(STRINGNOME) # Como tenho dados que não interessam a análise, # Extrai somente as linhas e colunas de interesse SCAN2[sujeito,,] = as.matrix(a[5:337, 5:337]) #pega somente as ROIS do atlas }#fecha for do sujeito Para cada indivíduo em S1, quero comparar para identificar a similaridade entre os indivíduos. Existem diversas formas para estimar isso, todavia, na conectividade é usual calcular por correlação (nesse caso utilizaremos a correlação entre os vetores).\nSendo a função “upper.tri” retorna se as caselas fazem parte ou não da triangular superior:\n# Criar matriz de similaridade entre individuos do Scan1 e Scan2: SIMILARIDADE = matrix(0, Nsujeitos, Nsujeitos) # Analisando as dimensões: dim(SCAN1) ## [1] 61 333 333 dim(SCAN2) ## [1] 61 333 333 dim(SIMILARIDADE) ## [1] 61 61 Interpretando o que queremos: Queremos que tenhamos a máxima correlação na diagonal principal entre os grupos, ou seja, que eu consiga identificar os mesmos sujeitos em scan2 e scan1.\n#Analise de Semelhanca entre conectomas funcionais #entre SCAN1 e SCAN2 for(sujeito in 1:Nsujeitos){ #extrair vetor com os valores da matriz triangular superior #superior das matrizes de correlacao do SCAN1 e SCAN2 conn1 = SCAN1[sujeito,,][which(upper.tri(SCAN1[sujeito,,])==TRUE)] for(sujeito2 in 1:Nsujeitos){ conn2 = SCAN2[sujeito2,,][which(upper.tri(SCAN2[sujeito2,,])==TRUE)] # metrica de similaridade # Lembrando que 1 seria o maximo SIMILARIDADE[sujeito, sujeito2] = cor(conn1, conn2) }#fecha for sujeito2 }#fecha for do sujeito Identificando as correlações:\nSIMILARIDADE[1:5, 1:5] ## [,1] [,2] [,3] [,4] [,5] ## [1,] 0.4288607 0.3453124 0.3083977 0.3062117 0.3717610 ## [2,] 0.3435626 0.5150018 0.3141666 0.2920438 0.3540784 ## [3,] 0.2975418 0.3088168 0.3602394 0.2884861 0.3667134 ## [4,] 0.2419438 0.2118502 0.1915199 0.3796243 0.2438880 ## [5,] 0.3297267 0.3452875 0.3205173 0.3101070 0.5760162 A diagonal principal dessa matriz indica a correlação correspondente de acertar os mesmos sujeitos.\nAgora identificando os indivíduos através da máxima correlação:\n#Identificacao dos individuos pela maxima correlacao em cada linha PREDICAO = array(0, Nsujeitos) for(sujeito in 1:Nsujeitos){ PREDICAO[sujeito] = which(SIMILARIDADE[sujeito,] == max(SIMILARIDADE[sujeito,]))[1] } #Acuracia da predicao length(which(PREDICAO-1:61 == 0))/Nsujeitos ## [1] 0.9344262 Como interpreto esse treco? Da contagem de 1:61 indivíduos, quero que a correlação no próximo scan seja compatível com 1:61 (ou seja, reconheça cada indivíduo).\nAnalisando a default-mode network:\n###### ANALISE DA DEFAULT-MODE NETWORK #Leitura do ID dos sujeitos nomes=scan(\u0026quot;CARAS.txt\u0026quot;,what=\u0026quot;string\u0026quot;) Nsujeitos=length(nomes) #Leitura do arquivo com o label das subredes cerebrais SUBREDES=read.table(\u0026quot;IDnet5-337.txt\u0026quot;)[,2] table(SUBREDES) ## SUBREDES ## Auditory CinguloOperc CinguloParietal ## 24 40 5 ## Default DorsalAttn FrontoParietal ## 41 32 24 ## None RetrosplenialTemporal Salience ## 47 8 4 ## SMhand SMmouth VentralAttn ## 38 8 23 ## Visual ## 39 ROIS=which(SUBREDES==\u0026quot;Default\u0026quot;) NROIS=length(ROIS) #Leitura da matriz de conectividade funcional de cada #individuo SCAN1=array(0,c(Nsujeitos,NROIS,NROIS)) SCAN2=array(0,c(Nsujeitos,NROIS,NROIS)) for(sujeito in 1:Nsujeitos){ # Leitura de dados do SCAN1 STRINGNOME=paste(\u0026quot;S1-GordonConnCOR-\u0026quot;,nomes[sujeito], \u0026quot;.txt\u0026quot;,sep=\u0026quot;\u0026quot;) a=read.table(STRINGNOME) SCAN1[sujeito,,]=as.matrix(a[5:337,5:337])[ROIS,ROIS] #pega somente as ROIS do atlas # Leitura de dados do SCAN2 STRINGNOME=paste(\u0026quot;S2-GordonConnCOR-\u0026quot;,nomes[sujeito], \u0026quot;.txt\u0026quot;,sep=\u0026quot;\u0026quot;) a=read.table(STRINGNOME) SCAN2[sujeito,,]=as.matrix(a[5:337,5:337])[ROIS,ROIS] #pega somente as ROIS do atlas }#fecha for do sujeito #Analise de Fingerprint #Matriz de similaridade entre sujeitos no SCAN2 e 1 SIMILARIDADE=matrix(0,Nsujeitos,Nsujeitos) for(sujeito in 1:Nsujeitos){ #Extrai valores da matriz triangular superior conn1=SCAN1[sujeito,,][which(upper.tri(SCAN1[sujeito,,])==TRUE)] for(sujeito2 in 1:Nsujeitos){ #Extrai valores da matriz triangular superior conn2=SCAN2[sujeito2,,][which(upper.tri(SCAN2[sujeito2,,])==TRUE)] SIMILARIDADE[sujeito,sujeito2]=cor(conn1,conn2) }}#fecha os for do sujeito #Identificacao dos individuos pela maxima correlacao PREDICAO=array(0,Nsujeitos) for(sujeito in 1:Nsujeitos){ PREDICAO[sujeito]=which(SIMILARIDADE[sujeito,]==max(SIMILARIDADE[sujeito,]))[1] } #Acuracia da predicao length(which(PREDICAO-1:61==0))/Nsujeitos ## [1] 0.9344262 Olhando as regiões, temos que em adultos, as regiões de funções mais básicas/primárias (visual, auditivo e SMhand) não possuem alta acurácia. Já as regiões superiores, que integram redes, identificam melhor os indivúduos (no caso DMN, frontoparietal, dorsolateral).\nAnalisando as redes superiores, é possível verificar que a identificação é bem-sucedida na verificação, indicando que o perfil de conectividade de um indivíduo é intrínseco e pode ser usado para diferenciá-lo, independentemente de como o cérebro está envolvido durante a geração de imagens.\nAs redes mais complexas ainda estão em evolução nas crianças, por isso a taxa de acurácia na infância é menor, em torno de 40%. As regiões significantes continuam sendo DMN, Frontoparietal e Dorsolateral, mas com menor acurácia pois seguem em constante desenvolvimento.\nE de fato, pesquisas mostram que padrões característicos de conectividade distribuídos por todo o cérebro, mas a rede frontoparietal emergiu como a mais distinta. Perfis de conectividade preveem níveis de inteligência fluida: as mesmas redes que eram mais discriminadoras de indivíduos também mostram ser as mais indicativas do comportamento cognitivo. Os resultados indicam o potencial para fazer inferências sobre assuntos individuais com base na conectividade funcional fMRI.\n"
},
{
	"uri": "/",
	"title": "Processamento de sinais neurais",
	"tags": [],
	"description": "",
	"content": "Essa página contém as notas da aula referentes ao curso de Processamento de Sinais Neurais dos cursos Bacharelado/Pós Graduação em Neurociência da UFABC.\nUtilize o menu ao lado para encontrar o conteúdo do curso.\nOs tópicos das aulas se encontram dentro do menu \u0026ldquo;Conteúdo\u0026rdquo; ao lado. As notas foram criadas em R Markdown, utilizando o R Studio.\nQuaisquer correções, erros e sugestões de acréscimos, favor entrar em contato com amanda.yumi at ufabc.edu.br\n"
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]